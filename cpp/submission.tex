\documentclass[sigplan,10pt,anonymous,review]{acmart}
\settopmatter{printfolios=true,printccs=false,printacmref=false}

\let\Bbbk\relax
\usepackage{isabellelst}

\title{Verification in Isabelle/HOL of a Set-based Algorithm for Computing Strongly Connected Components}

\author{Stephan Merz}
\orcid{0000-0003-0974-1844}
\affiliation{
  \institution{University of Lorraine, CNRS, Inria, LORIA}
  \city{Nancy}
  \country{France}
}

\author{Vincent TrÃ©lat}
%\orcid{0000-0003-0974-1844}
\affiliation{
  \institution{University of Lorraine}
  \city{Nancy}
  \country{France}
}

\keywords{graph algorithm, strongly connected component, formal verification, interactive theorem proving}

\newcommand{\prog}[1]{\textit{#1}}
\renewcommand{\SS}{\mathcal{S}}
\usepackage{array}
\newcolumntype{M}[1]{>{\centering\arraybackslash}m{#1}}

% ----------------------------------------------------------------------
\begin{document}
\begin{abstract}
  The efficient computation of strongly connected components in a directed graph is a fundamental algorithmic problem with applications in many fields of computer science. We report on the formal verification of a recent algorithm proposed by Bloemen in the proof assistant Isabelle/HOL. Our work is intended as a stepping stone towards a correctness proof of the parallel version of that algorithm, which has been implemented in the high-performance model checker LTSmin.
\end{abstract}

\maketitle

\section{Introduction}
\label{sec:introduction}

Directed graphs are widely used in many fields of computer science and mathematics, and they are the source of many interesting algorithmic problems. A fundamental problem is the computation of strongly connected components (SCCs) of a graph, that is, maximal sets~$S$ of vertices such that all vertices in~$S$ are reachable from every other vertex in~$S$ \cite[Chap.~4.2]{sedgewick:algorithms}. Among many other applications, computing SCCs underlies algorithmic techniques for system verification, such as model checking, that are applied to ensure the correctness of safety-critical systems in domains including nuclear energy, aerospace, aeronautics, medical applications, and the railway industry. An error in an algorithm for computing SCCs or in its implementation could therefore jeopardize the verdict produced by a model checker. Recognizing the importance of this problem, a seminal result about the formal verification of model checkers was the work by Esparza et al.~\cite{esparza:cava} on the formal proof of an executable model checker for LTL, later extended to also include techniques for partial order reduction~\cite{brunner:partial-order}.

Several different algorithms exist for efficiently computing SCCs of a graph. Perhaps the most famous one is Tarjan's algorithm~\cite{tarjan:depth-first}. It performs a depth-first traversal of the nodes of the graph. When it encounters an edge that leads to an already visited node that is part of the current DFS path, it detects a cycle, and it tracks (via additional information stored for the encountered nodes) which nodes belong to the same SCC. Dijkstra~\cite{dijkstra:finding} suggested a variant of a DFS traversal where the stack contains roots of (partial) SCCs. When a cycle is detected, the corresponding partial SCCs are collapsed, shortening the stack. Both algorithms are efficient because they operate in time $O(|V|+|E|)$ where $V$ and $E$ denote the sets of nodes and edges of the graph, since every node and every edge is visited only once during the traversal, but they differ in their algorithmic structure and in the auxiliary information that must be stored.

However, both these algorithms and their numerous variants are fundamentally sequential because their correctness crucially relies on the graph being traversed in DFS order. Bloemen et al.~\cite{bloemen:strong,bloemen:multi-core} introduced a variant of Dijkstra's algorithm for computing SCCs that can be implemented on a shared-memory multi-core processor, based on efficient data structures for (i) implementing a union-find structure representing partial SCCs and (ii) a cyclic list for iterating over states, that minimize locking. This algorithm has been implemented in the high-performance model checker LTSmin. The correctness proofs in Bloemen's thesis are based on ordinary paper-and-pencil reasoning and therefore do not correspond to the same exacting standards as the machine-checked verification of model checking algorithms mentioned above. The problem is particularly delicate given that a multi-core implementation of the algorithm need not strictly adhere to a DFS traversal order, and any core may revisit nodes that have already been visited by other cores.

The present work makes a first contribution towards a machine-checked proof of the SCC algorithm by Bloemen et al.\ by establishing the correctness of the sequential version of the algorithm. Although this is arguably less challenging than the proof of the parallel version, we consider it to be a necessary first step that establishes a baseline against which the parallel algorithm can be compared. In particular, we exhibit inductive invariants that ensure the correctness of the sequential algorithm, and it then becomes meaningful to consider which invariants can be relaxed in a parallel execution. We are interested in the correctness of the high-level algorithm and therefore do not consider the concrete representation of the data structures on which it relies, or the generation of efficiently executable code implementing the sequential algorithm.


\paragraph{Outline of the paper.}

Section~\ref{sec:background} introduces necessary background for our work, in particular the proof assistant Isabelle/HOL and our representation of finite directed graphs and strongly connected components. Our encoding of Bloemen's algorithm in Isabelle is described in Section~\ref{sec:formalization}. The presentation of the correctness proof appears in Sections~\ref{sec:partial-correctness}, introducing the main invariants and the pre- and post-conditions used in the proof of partial correctness, whereas Section~\ref{sec:termination} explains the proof of termination. An assessment of the proof effort appears in Section~\ref{sec:effort}, related work is discussed in Section~\ref{sec:related}, and Section~\ref{sec:conclusion} contains a summary of the work and some perspectives for future work.


\section{Background}
\label{sec:background}

\subsection{Isabelle}
\label{sec:isabelle}

Isabelle~\cite{paulson:isabelle} is a generic logical framework in which different object logics can be encoded. Isabelle/HOL~\cite{nipkow:isabelle} is the instance of Isabelle for higher-order logic, which we use in our work and which we will refer to in the following simply as Isabelle. It provides an expressive formal language for representing formal mathematical theories, including the formalization of algorithms and their correctness proofs, and it comes with an extensive standard library of operator definitions and lemmas, and with tools for defining \emph{locales} (algebraic structures parameterized by operators and assumptions), \emph{inductive definitions} of sets and relations, (mutually) \emph{recursive functions} etc.

Isabelle belongs to the LCF family of proof assistants whose soundness is ensured by a comparatively small trusted kernel that serves to certify proofs. In particular, theorems are represented by an inductive data type whose constructors correspond to the instantiation of elementary axioms and the application of rules, typically provided by the definition of the object logic. From the user's point of view, Isabelle proofs are written in the Isar (``Intelligible Semi-Automated Reasoning'') language that is designed to make proofs readable and comprehensible for a mathematically inclined reader, with minimal overhead introduced by the formalism. Extensive automation is provided by built-in proof procedures based on rewriting and first-order reasoning, as well as by the \emph{Sledgehammer}~\cite{blanchette:sledgehammer} add-on that selects potentially relevant lemmas from the context (including the standard proof library), calls external automatic proof backends such as SMT solvers or automatic proof tools for first-order and higher-order logic, and in case of success applies back-end provers whose proofs can be reconstructed in the trusted kernel.

As part of the standard library, we have the pre-defined types $\alpha~\prog{set}$ of (possibly infinite) sets of elements of type~$\alpha$, and $\alpha~\prog{list}$ of (finite) lists over~$\alpha$. The latter is constructed by the empty list $[]$ and the \emph{cons} function, written $x\ \#\  xs$, that prepends an element $x$ to a list $xs$. The \prog{hd} and \prog{tl} functions access the head and the tail of a non-empty list. The concatenation of two lists $xs$ and $ys$ is denoted as $xs\ @\ ys$. In addition, we define the predicate

\begin{small}
\begin{lstlisting}[language=isabelle]
  x prec y in xs
\end{lstlisting}
\end{small}
%
that holds if the elements $x$ and $y$ both occur in the list $xs$, and $x$ has an occurrence to the left of an occurrence of $y$ in $xs$. For a \prog{distinct} list~$xs$ (i.e., a list without duplicate elements), this predicate defines a partial order on the elements of~$xs$.


\subsection{Graphs and strongly connected components}
\label{sec:graphs}

We represent finite directed graphs with nodes of type $\nu$ as an Isabelle locale that fixes a finite set of vertices and a successor function associating to each node a set of successor nodes.

\begin{small}
\begin{lstlisting}[language=isabelle]
locale graph =
  fixes   vertices :: 'v set
  and     successors :: 'v => 'v set
  assumes finite vertices  
  and     forall v sin vertices. successors v subseteq vertices
\end{lstlisting}
\end{small}

Reachability in graphs is defined inductively as follows.

\begin{small}
\begin{lstlisting}[language=isabelle]
inductive reachable where
  reachable-refl: reachable x x
| reachable-succ: [| y sin successors x; reachable y z |]
                  ==> reachable x z
\end{lstlisting}
\end{small}

Elementary lemmas, such as the transitivity of the reachability relation, are easily proved by induction, followed by an application of Isabelle's automatic proof methods. For our later proofs, we also need the following variant of reachability between nodes avoiding a set $E$ of edges.

\begin{small}
\begin{lstlisting}[language=isabelle]
inductive reachable-avoiding where
  ra-refl: reachable-avoiding x x E
| ra-succ: [| y sin successors x; (x,y) notin E; 
             reachable-avoiding y z E |] 
           ==> reachable-avoiding x z E
\end{lstlisting}
\end{small}

Again, this relation is transitive, it implies reachability, is anti-monotonic in the set $E$, and reachability agrees with reachability avoiding the empty set of edges. More interestingly, we show the following lemma about adding an edge to the set~$E$ of forbidden edges.

\begin{small}
\begin{lstlisting}[language=isabelle]
lemma ra-add-edge:
  assumes reachable-avoiding x y E
  shows   reachable-avoiding x y (E cup {(v,w)})
        \/ reachable-avoiding x v (E cup {(v,w)})
           /\ reachable-avoiding w y (E cup {(v,w)})
\end{lstlisting}
\end{small}

Strongly connected components are of particular importance for stating the correctness of our algorithm. A partial SCC is a set $S$ of nodes all of which are reachable from each other. In particular, a cycle in a graph constitutes a partial SCC. A maximal SCC is a non-empty partial SCC such that none of its supersets is a partial SCC. In the following, when we write SCC, we refer to a maximal SCC.

\begin{small}
\begin{lstlisting}[language=isabelle]
definition is-subscc where
  is-subscc S == forall x sin S. forall y sin S. reachable x y

definition is-scc where
  is-scc S == S noteq {} /\ is-subscc S
              /\ (forall S'. S subseteq S' /\ is-subscc S'
                       --> S' = S)
\end{lstlisting}
\end{small}

Sledgehammer finds a one-line proof showing that two SCCs are either disjoint or identical:

\begin{small}
\begin{lstlisting}[language=isabelle]
lemma scc-partition:
  assumes is-scc S and is-scc S' and x sin S cap S'
  shows   S = S'
\end{lstlisting}
\end{small}


\section{Formalization of Bloemen's Algorithm in Isabelle/HOL}
\label{sec:formalization}

We represent the data on which the algorithm operates as an ``environment'' record with the following components:

\begin{small}
\begin{lstlisting}[language=isabelle]
record 'v env =
  root :: 'v
  SS :: 'v => 'v set
  visited :: 'v set
  explored :: 'v set
  sccs :: 'v set set
  stack :: 'v list
  cstack :: 'v list
  vsuccs :: 'v => 'v set
\end{lstlisting}
\end{small}

The \prog{root} component stores the node for which the algorithm was originally called.
The function $\SS$ maps every node~$v$ to the set of nodes that have already been determined to be part of the same SCC as~$v$.
%At the beginning of the execution, every node $v$ is mapped to the singleton component $\{v\}$.
A core invariant of the algorithm will be that this mapping represents a partition of nodes into sets of equivalence classes: for all nodes~$v$ and~$w$, we maintain the relationship
\[
  v \in \SS~w\ \longleftrightarrow\ \SS~v = \SS~w.
\]
The sets \prog{visited} and \prog{explored} represent the sets of nodes that have already been seen, respectively fully explored, by the algorithm, and \prog{sccs} is the set of (maximal) SCCs that the algorithm has detected so far. Variable \prog{stack} holds the roots of the (partial) SCCs of visited, but not fully explored nodes, in depth-first order, whereas \prog{cstack} represents the call stack of the main function \prog{dfs} of the algorithm. Finally, \prog{vsuccs} remembers the set of outgoing edges (represented by the target nodes) of each node that have already been followed during the exploration. Let us observe that the variables \prog{root} and \prog{cstack} are not actually accessed by the algorithm: they are ghost variables used in the correctness proof.

The algorithm is initially called with an environment of the form $\prog{init-env}~v$ that holds $v$ as the root node, initializes $\SS$ by assigning the singleton $\{u\}$ to every node $u$, and has all other components initialized to the empty set or the empty list.

Environments are partially ordered according to the following relation.

\begin{small}
\begin{lstlisting}[language=isabelle]
definition sub-env where
sub-env e e' ==
    root e' = root e
  /\ visited e subseteq visited e'
  /\ explored e subseteq explored e'
  /\ (forall v. vsuccs e v subseteq vsuccs e' v)
  /\ (forall v. SS e v subseteq SS e' v)
  /\ (Union {SS e v | v. v sin set (stack e)})
     subseteq (Union {SS e' v | v. v sin set (stack e')})
\end{lstlisting}
\end{small}

We follow the definition of the algorithm in~\cite{bloemen:strong}, but represent it as a pair of mutually recursive functions \prog{dfs} and \prog{dfss} defined as follows.

\begin{small}
\begin{lstlisting}[language=isabelle]
function dfs  :: 'v => 'v env => 'v env
and      dfss :: 'v => 'v env => 'v env where
  dfs v e =
    let e1 = e(| visited := visited e cup {v},
                stack := v # stack e,
                cstack := v # cstack e |);
        e' = dfss v e1
    in  if v = hd (stack e')
        then e'(| sccs := sccs e' cup {SS e' v},
                 explored := explored e' cup SS e' v,
                 stack := tl (stack e'),
                 cstack := tl (cstack e') |)
        else e'(| cstack := tl (cstack e') |)
| dfss v e =
    let vs = successors v - vsuccs e v
    in  if vs = {} then e
        else let w = SOME x. x sin vs;
                 e' = (if w sin explored e then e
                       else if w notin visited e
                            then dfs w e
                            else unite w e);
                 e'' = e'(| vsuccs := lambda x. 
                              if x = v 
                              then vsuccs e' v cup {w}
                              else vsuccs e' x|)
             in dfss v e''
\end{lstlisting}
\end{small}

Function \prog{dfs} explores a node $v$ by adding it to the set of visited nodes, pushing it on both stacks, and then calling the function \prog{dfss}. If $v$ is still at the head of the stack when the call to \prog{dfss} returns, the SCC to which $v$ belongs is added to the set of maximal SCCs, all its nodes are marked as fully explored, and $v$ is popped from both stacks. Otherwise, $v$ is not the root node of the SCC to which it belongs and is therefore no longer contained in the stack, but it is popped from the call stack. The tail-recursive function \prog{dfss} iterates over all successors $w$ of node $v$. If $w$ has already been fully explored, there is nothing to do. If $w$ has not been seen before, the function \prog{dfs} is called for $w$, otherwise the algorithm detects a loop back to a node that has already been visited. Therefore, the root node~$r$ of the SCC to which~$w$ belongs must be on the stack. The partial SCCs of all nodes contained in the prefix\footnote{Note that the top of the stack is at the head of the list.} of the stack up to node~$r$ are collapsed, using the following auxiliary function.

\begin{small}
\begin{lstlisting}[language=isabelle]
definition unite :: 'v => 'v env => 'v env where
unite w e ==
  let pfx = takeWhile (lambda x. w notin SS e x) (stack e);
      sfx = dropWhile (lambda x. w notin SS e x) (stack e);
      cc = Union { SS e x | x . x sin set pfx cup {hd sfx} }
  in  e(| SS := lambda x. if x sin cc then cc else SS e x;
          stack := sfx |)
\end{lstlisting}
\end{small}

In words, \prog{unite} computes the prefix of the stack consisting of the roots of partial SCCs that do not contain $w$. Since $w$ must be represented by some node on the stack, the remaining suffix is non-empty, and $\SS~(\prog{hd}~\prog{sfx})$ contains $w$. A new connected component $\prog{cc}$ is computed by taking the union of the partial SCCs represented by the nodes in the prefix, as well as the head of the suffix. The mapping $\SS$ is updated so that all nodes in $\prog{cc}$ are mapped to $\prog{cc}$, and the stack is shortened to the suffix of the previous stack, implicitly making the head of that suffix the root of the component $cc$.

Internally, Isabelle generates a single function \prog{dfs-dfss} whose argument type is the sum of the argument types for the individual functions, and defines the latter as projections of the combined function. Auto-generated theorems, such as computational induction, simultaneously handle both functions in order to enable mutual induction. A technical complication in the definition of the algorithm is that the functions \prog{dfs} and \prog{dfss} need not terminate when their pre-conditions (defined below) are violated. We will come back to proving termination in Section~\ref{sec:termination}.


\section{Proof of Partial Correctness}
\label{sec:partial-correctness}

\subsection{Main invariant}
\label{sec:invariant}

We define \emph{well-formed} environments to be those satisfying the following conditions, and we will prove this predicate to hold throughout the execution of the algorithm.

\begin{small}
\begin{lstlisting}[language=isabelle]
definition wf-env where
wf-env e ==
    (forall n sin visited e. reachable (root e) n)
  /\ distinct (stack e)
  /\ distinct (cstack e)
  /\ (forall n m. n prec m in stack e --> n prec m in cstack e)
  /\ (forall n m. n prec m in stack e --> reachable m n)
  /\ explored e subseteq visited e
  /\ set (cstack e) subseteq visited e
  /\ (forall n sin explored e. forall m. 
        reachable n m --> m sin explored e)
  /\ (forall n. vsuccs e n subseteq successors n cap visited e)
  /\ (forall n. n notin visited e --> vsuccs e n = {})
  /\ (forall n sin explored e. vsuccs e n = successors n)
  /\ (forall n sin visited e - set (cstack e). 
        vsuccs e n = successors n)
  /\ (forall n m. m sin SS e n <--> SS e n = SS e m)
  /\ (forall n. n notin visited e --> SS e n = {n})
  /\ (forall n sin set (stack e). forall m sin set (stack e).
        n noteq m --> SS e n cap SS e m = {})
  /\ Union {SS e n | n. n sin set (stack e)} 
     = visited e - explored e
  /\ (forall n in set (stack e). forall m in SS e n.
        m sin set (cstack e) --> m prec n in cstack e)
  /\ (forall n m. n prec m in stack e /\ n noteq m -->
        (forall u sin SS e n. ~ reachable-avoiding u m 
                                    (unvisited e n)))
  /\ (forall n. is-subscc (SS e n))
  /\ (forall S sin sccs e. is-scc S)
  /\ Union (sccs e) = explored e
\end{lstlisting}
\end{small}

In words, every visited node is reachable from the root node, the two stacks contain every node at most once, and the stack of SCC roots is a subsequence of the call stack. Nodes on the stack are reachable from all stack nodes below them. All explored nodes, as well as all nodes on the call stack (hence also the nodes on the stack of SCC roots), are visited. All nodes reachable from fully explored nodes are themselves fully explored. The visited successors of a node are both successors and visited, and an unvisited node has no visited successors. All outgoing edges of fully explored nodes, as well as of visited nodes that are no longer on the call stack, have been followed. The mapping $\SS$ represents an equivalence relation, as discussed above, and it maps an unvisited node $n$ to the singleton $\{n\}$. The nodes on the stack are roots of partial SCCs, hence their equivalence classes are disjoint. A node has been visited but not yet fully explored iff the root node of the associated partial SCC is on the stack. Moreover, root nodes of partial SCCs are the oldest nodes in depth-first order. No node $u$ belonging to the SCC of a node $n$ on the stack can reach a node $m$ strictly below $n$ on the stack without going through an edge from some node in $n$'s equivalence class that has not yet been followed. In other words, the partial SCCs are maximal with respect to the current knowledge of the algorithm. Given a node~$n$, the set of edges that leave some node in the equivalence class of~$n$ and have not yet been followed is defined as
%
\begin{small}
\begin{lstlisting}[language=isabelle]
definition unvisited where
unvisited e n ==
  {(a,b) | a b. a sin SS e n 
              /\ b sin successors a - vsuccs e a}
\end{lstlisting}
\end{small}
%
Finally, every equivalence class is a (partial) SCC, elements of \prog{sccs} are maximal SCCs, and the union of their nodes is the set of explored nodes.

%% Not sure if we need this ...
We prove a number of simple consequences of this predicate. For example, if $e$ is a well-formed environment then $n \in \SS~e~n$ holds for every node~$n$. If node $w$ is reachable from a visited node $v$, but not through any edge that has not yet been followed, then $w$ must be visited. Also, edges towards fully explored nodes do not contribute to reachability of not fully explored nodes avoiding some set of edges:
%
\begin{small}
\begin{lstlisting}[language=isabelle]
lemma avoiding-explored:
assumes wf-env e and reachable-avoiding x y E
    and y notin explored e and w sin explored e
shows   reachable-avoiding x y (E cup {(v,w)})
\end{lstlisting}
\end{small}


\subsection{Pre- and post-conditions of the functions}
\label{sec:pre-post}

The proof of partial correctness of the algorithm relies on the fact that the environment produced by a call of \prog{dfs} for arguments that satisfy certain hypotheses (the pre-conditions) satisfies certain other properties (the post-conditions). Because of the mutual recursion between the two functions, we must define pre- and post-conditions for both \prog{dfs} and \prog{dfss}.

First, we define pre- and post-conditions for function \prog{dfs}.

\begin{small}
\begin{lstlisting}[language=isabelle]
definition pre-dfs where 
  pre-dfs v e ==
    wf-env e
  /\ v notin visited e
  /\ reachable (root e) v
  /\ (forall n sin set (stack e). reachable n v)
\end{lstlisting}
\end{small}

Function \prog{dfs} should be called for a well-formed environment and a node $v$ that has not yet been visited and that is reachable from the root node, as well as from all nodes in the stack.
% In fact, this is a consequence of wf-env e and v \notin visited e, and can be dropped.
% No outgoing edges from node $v$ have yet been followed.

\begin{small}
\begin{lstlisting}[language=isabelle]
definition post-dfs where 
  post-dfs v e e' ==
    wf-env e'
  /\ sub-env e e'
  /\ v sin visited e'
  /\ vsuccs e' v = successors v
  /\ (forall w sin visited e. vsuccs e' w = vsuccs e w)
  /\ (exists ns. stack e = ns @ (stack e'))
  /\ cstack e' = cstack e
  /\ ((v sin explored e' /\ stack e' = stack e 
      /\ (forall n sin set (stack e'). SS e' n = SS e n)) 
    \/ (stack e' noteq [] /\ v sin SS e' (hd (stack e')) 
      /\ (forall n sin set (tl (stack e')). SS e' n = SS e n)))
\end{lstlisting}
\end{small}

Function \prog{dfs} produces a well-formed environment $e'$ that extends the input environment $e$. Node $v$ has been visited and all its outgoing edges have been followed. Because the algorithm works in depth-first fashion, no new outgoing edges of nodes that were already visited in the input environment have been followed, and the stack of SCC roots in $e'$ is a suffix of the corresponding stack of $e$.
% Again, this follows from the pre-condition and the suffix property.
% such that $v$ is still reachable from all nodes on the stack. 
In particular, the stack may have been shortened because SCCs represented at the top of the stack may have been merged. The call stack is reestablished as it was in $e$. There are two possible outcomes of the algorithm:
\begin{itemize}
\item Either $v$ has been fully explored, in which case the stacks of $e$ and $e'$ are the same, and the partial SCCs of all nodes represented on the stack are unchanged. This corresponds to the case where $v$ is the root node of its (maximal) SCC.
\item Alternatively, the stack of $e'$ must be non-empty and $v$ must be a member of the partial SCC of the node at the top of the stack. The partial SCCs represented by the stack elements other than the top are unchanged. This corresponds to the case where $v$ is not the root node of its SCC, and some partial SCCs at the top of the stack may have been merged.
\end{itemize}

We now define pre- and post-conditions for function \prog{dfss}.

\begin{small}
\begin{lstlisting}[language=isabelle]
definition pre-dfss where 
  pre-dfss v e ==
    wf-env e 
  /\ v sin visited e
  /\ stack e noteq []
  /\ v sin SS e (hd (stack e))
  /\ (forall w sin vsuccs e v.
      w sin explored e cup SS e (hd (stack e)))
  /\ (forall n sin set (stack e). reachable n v)
  /\ (exists ns. cstack e = v # ns)
\end{lstlisting}
\end{small}

The pre-condition of function \prog{dfss} corresponds to the invariant of the loop over all outgoing edges from node~$v$. The environment is well-formed, node~$v$ has been visited and is represented by the top of the (non-empty) stack, it is reachable from all nodes on the stack, and it is the top node on the call stack. All outgoing edges of node $v$ that have already been followed either lead to completely explored nodes or to nodes that are part of the same SCC as~$v$.

Function \prog{dfss} establishes the following post-condition:

\begin{small}
\begin{lstlisting}[language=isabelle]
definition post-dfss where 
  post-dfss v e e' == 
     wf-env e'
   /\ sub-env e e'
   /\ vsuccs e' v = successors v
   /\ (forall w sin visited e - {v}. vsuccs e' w = vsuccs e w)
   /\ (forall w sin successors v.
        w sin explored e' cup SS e' (hd (stack e')))
   /\ (forall n sin set (stack e'). reachable n v)
   /\ (stack e' noteq [])
   /\ (exists ns. stack e = ns @ (stack e'))
   /\ cstack e' = cstack e
   /\ v sin SS e' (hd (stack e'))
   /\ (forall n sin set (tl (stack e')). SS e' n = SS e n)
   /\ (hd (stack e') = v -->
        (forall n sin set (tl (stack e')). ~ reachable v n))
\end{lstlisting}
\end{small}

In the same way as function \prog{dfs}, function \prog{dfss} ensures that the resulting environment $e'$ is well-formed and extends the input environment $e$, that all outgoing edges of $v$ have been followed, and that the sets of visited successors of previously visited nodes other than $v$ are unchanged. The new stack is non-empty, it is a suffix of the old stack, and the call stack is restored. The partial SCCs corresponding to nodes in the stack other than the top stack element are left untouched. In case node $v$ is still on the stack (and is therefore the root node of its partial SCC), no stack node below $v$ can be reached from $v$. This condition is important for ensuring that the computed SCC is in fact maximal.


\subsection{Lemmas establishing the pre-conditions}
\label{sec:pre-pre}

First, it is easy to see (and Isabelle proves automatically) that the initial environment satisfies the pre-condition of function \prog{dfs}.

\begin{small}
\begin{lstlisting}[language=isabelle]
lemma init-env-pre-dfs: pre-dfs v (init-env v)
\end{lstlisting}
\end{small}

Given that the two functions \prog{dfs} and \prog{dfss} mutually call each other, we need to establish the pre-condition of the called function, assuming the pre-condition of the calling function.

For example, the following lemma asserts that the pre-condition of \prog{dfss} holds at the call from the body of \prog{dfs}. Although some of the well-formedness conditions for the augmented environment require a few lines of interaction, the overall proof is straightforward.

\begin{small}
\begin{lstlisting}[language=isabelle]
lemma pre-dfs-pre-dfss:
  assumes pre-dfs v e
  shows   pre-dfss v (e(| visited := visited e cup {v},
                         stack := v # stack e,
                         cstack := v # cstack e |))
\end{lstlisting}
\end{small}

The following lemma asserts the pre-condition of the recursive call to \prog{dfs} from \prog{dfss} for a successor that has not been visited yet. Its proof is entirely automatic, helped by the fact that the environment of the call to \prog{dfs} is unchanged.

\begin{small}
\begin{lstlisting}[language=isabelle]
lemma pre-dfss-pre-dfs:
  assumes pre-dfss v e
  and     w sin successors v - visited e
  shows   pre-dfs w e
\end{lstlisting}
\end{small}

Finally, we need to show the pre-condition of \prog{dfss} at the call of \prog{dfss} at the end of the function body, i.e.\ the preservation of the loop invariant. We state three separate lemmas according to the branch of the conditional in the computation of the intermediate environment $e'$ in the body of \prog{dfss}. As an example, we show the statement of the lemma corresponding to the third branch.

\begin{small}
\begin{lstlisting}[language=isabelle]
lemma pre-dfss-unite-pre-dfss:
  fixes e v w
  defines e' = unite w e
  defines e'' = e'(| vsuccs := (lambda x. if x = v 
                                then vsuccs e' v cup {w}
                                else vsuccs e' v) |)
  assumes pre-dfss v e
  and     w sin successors v - vsuccs e
  and     w sin visited e
  and     w notin explored e
  shows   pre-dfss v e''
\end{lstlisting}
\end{small}

Some steps in the proof of this lemma require a substantial number of interactions. We start by proving several auxiliary lemmas about function \prog{unite}, including the fact that the intermediate environment $e'$ is well-formed. Then, we have to show that this invariant also holds for $e''$. For example, given two nodes $x \neq y$ such that $x$ precedes $y$ in the stack of $e''$ (which is the same as the stack of $e'$) and a node $u \in \SS~e''~x = \SS~e'~x$, we must show that $y$ can be reachable from $u$ only by following some edge in $\prog{unvisited}~e''~x$. Therefore, assume that $y$ is reachable from $u$ avoiding all edges in $\prog{unvisited}~e''~x$. The proof proceeds by a case analysis depending on whether $x$ is the head of $\prog{stack}~e'$ or not.

In case it is, the definitions of \prog{unvisited} and of $e''$ imply that either $\prog{unvisited}~e'~x = \prog{unvisited}~e''~x$ or $\prog{unvisited}~e'~x = \prog{unvisited}~e''~x \cup \{(v,w)\}$. In the first case, we can conclude directly by appealing to the well-formedness of $e'$. In the second case, lemma \prog{ra-add-edge} tells us that either $y$ is reachable from $u$ avoiding edges in $\prog{unvisited}~e'~x$ or that $y$ is reachable from $w$ avoiding the same set of edges. In the first case, we again conclude appealing to the well-formedness of $e'$. In the second case, we know that $w \in \SS~e'~x$ (since $x$ is the head of $\prog{stack}~e'$) and therefore find another contradiction to the well-formedness of $e'$.

In case $x$ is not the head of $\prog{stack}~e'$, both nodes $x$ and $y$ must already be elements of $\prog{stack}~e$, with $x$ still preceding $y$. Also, the pre-condition $\prog{pre-dfss}~v~e$ implies that $v$ is a member of the partial SCC represented by the head of the stack, and using the well-formedness of $e$ it follows that $v \notin \SS~e'~x$ and therefore $\prog{unvisited}~e''~x = \prog{unvisited}~e'~x = \prog{unvisited}~e~x$. We can now conclude by appealing to the well-formedness of the environment $e$.


\subsection{Pre-conditions imply post-conditions}
\label{sec:pre-post}

The following lemma is central for the proof of partial correctness: it shows that the functions \prog{dfs} and \prog{dfss} establish their respective post-conditions, assuming that the pre-conditions hold for the input parameters. Because we have not yet proved termination of the functions, we need an additional hypothesis for each statement that, intuitively, asserts that the corresponding function will terminate for its input parameters.

\begin{small}
\begin{lstlisting}[language=isabelle]
lemma pre-post:
  [| dfs-dfss-dom (Inl (v,e)); pre-dfs v e |] 
     ==> post-dfs v e (dfs v e)
  [| dfs-dfss-dom (Inr (v,e)); pre-dfss v e |]
     ==> post-dfss v e (dfss v e)
\end{lstlisting}
\end{small}

Since the two functions are mutually recursive, the two statements must be proved by simultaneous computational induction, using the corresponding proof rule generated by Isabelle. The proofs of these implications again involve a certain number of steps requiring substantial interaction.

As an example, in the first branch of the conditional in the body of function \prog{dfs} we need to prove that all nodes~$y$ reachable from an explored node $x$ are themselves explored. The interesting case occurs when $x \in \SS~e'~v$, where $e'$ denotes the environment computed by the call to \prog{dfss}. Because $\SS~e'~v$ is a partial SCC, node~$x$ is reachable from node~$v$. We first show that $y \in \prog{visited}~e'$. Otherwise, given that $x \in \prog{visited}~e'$, by induction we obtain nodes $n \in \prog{visited}~e'$ and $m \in \prog{successors}~n - \prog{vsuccs}~e'~n$ (i.e., $m$ is an unvisited successor of~$n$) such that $n$ is reachable from~$x$ and $y$ is reachable from~$m$. But then, we have $n \notin \prog{explored}~e'$ since all successors of explored nodes have been visited, hence there must be a node $n' \in \prog{set}~(\prog{stack}~e')$ such that $n \in \SS~e'~n'$. Using the last conjunct of the post-condition \prog{post-dfss}, it follows that $n' = v$, for otherwise $v$ could reach a node deeper in the stack. But then, we have $n \in \SS~e'~v \subseteq \prog{explored}~e'$, and according to another conjunct of the invariant that we already proved earlier, we must have $\prog{successors}~n = \prog{vsuccs}~e'~n$, reaching a contradiction.

We now prove $y \in \prog{explored}~e''$, where $e''$ denotes the environment resulting from the call to \prog{dfs}. If $y \in \prog{explored}~e'$, this is clearly true. Otherwise, given that $y \in \prog{visited}~e'$, we obtain some node $n \in \prog{set}~(\prog{stack}~e')$ such that $y \in \SS~e'~n$. If $n=v$, the assertion follows by the definition of $e''$. Otherwise, $n$ is a stack node below $v$ that is reachable from~$v$ via nodes~$x$ and~$y$, contradicting the last conjunct of the post-condition \prog{post-dfss}.

From the lemmas proved so far, we can infer the partial correctness of the function \prog{dfs} when called with the initial environment.

\begin{small}
\begin{lstlisting}[language=isabelle]
theorem partial-correctness:
  assumes dfs-dfss-dom (Inl (v, init-env v)
  shows   sccs (dfs v (init-env v)) = 
          {S . is-scc S /\ (forall n sin S. reachable v n)}
\end{lstlisting}
\end{small}

In words, assuming that function \prog{dfs} terminates for the input parameters, it computes the set of all maximal SCCs in the sub-graph reachable from node~$v$. In particular, if $v$ is a root node of the graph, all maximal SCCs of the graph will be computed.



\section{Proof of Termination}
\label{sec:termination}

Informally, the algorithm terminates because (i) whenever function \prog{dfs} is called for arguments~$v$ and~$e$, the node~$v$ will be added to the set of \prog{visited} nodes (and therefore the complement of that set w.r.t.\ the finite set of vertices decreases) and (ii) every call of function $\prog{dfss}~v~e$ either terminates immediately or adds a new node $w$ to $\prog{vsuccs}~e~v$. Observe that these conditions can be established only if the calls respect the pre-conditions: for example, (i) does not hold if~$v$ was already visited at the call of \prog{dfs}. We now explain how we make this argument formal and prove termination of the algorithm, assuming the pre-conditions.

As a first step, we define the following relation on argument tuples of the two functions.\footnote{Remember that \prog{Inl} and \prog{Inr} inject arguments of function \prog{dfs}, respectively \prog{dfss}, into the sum type representing arguments of the pair of functions.}

\begin{small}
\begin{lstlisting}[language=isabelle]
definition dfs-dfss-term where dfs-dfss-term ==
  { (Inr (v,e1), Inl (v,e)) | v e e1.
    v sin vertices - visited e 
    /\ visited e1 = visited e cup {v} }
cup { (Inl (w,e), Inr (v,e)) | v w e. v sin vertices }
cup { (Inr (v,e''), Inr (v,e)) | v e e''.
    v sin vertices /\ sub-env e e''
    /\ (exists w sin vertices. w sin vsuccs e'' v - vsuccs e v) }
\end{lstlisting}
\end{small}

This relation over-approximates the pairs of argument tuples for which recursive calls occur. For example, the first set in the above definition represents calls of \prog{dfss} from \prog{dfs} where $v$ was not visited at the call of \prog{dfs} but is added to the set of visited nodes at the call of \prog{dfss}. Observe that the second set, which corresponds to the call of \prog{dfs} from \prog{dfss}, requires that the call environment remains unchanged and in particular does not impose an immediate increase of either set \prog{visited} or \prog{vsuccs}. However, the use of different injection functions implies that one cannot construct a cycle using these argument tuples.

Crucially, we prove that the relation \prog{dfs-dfss-term} is well-founded.

\begin{small}
\begin{lstlisting}[language=isabelle]
lemma wf-term: wf dfs-dfss-term
\end{lstlisting}
\end{small}

In the statement of the lemma, \prog{wf} represents the well-foundedness predicate, which is predefined in the Isabelle standard library. The lemma is proved by embedding the argument tuples into triples $(a,b,c)$ where $a$ is the set of unvisited vertices, $b$ is the set of edges between vertices that have not been followed, and $c$ is $0$ if the triple represents an argument of \prog{dfs} and $1$ if it is an argument of \prog{dfss}. These triples can be ordered by the strict subset order for the two first components and the predecessor relation on natural numbers for the third one, and Isabelle proves automatically that the product of these orders is well-founded. Finally, \prog{dfs-dfss-term} can be embedded as an inverse image in this well-founded relation, and is therefore itself well-founded.

\begin{table*}
  \centering
  \begin{tabular}{|l|r|r|}
    \hline
    Category                         &  Definitions   &  Theorems and proofs\\
    \hline\hline
    Precedence on lists              &        2 loc   &         119 loc\\
    \hline
    Graphs and reachability          &       15 loc   &          64 loc\\
    \hline
    Formalization of the algorithm   &       64 loc   &           6 loc\\
    \hline
    Invariants, pre-/post-conditions &       68 loc   &         120 loc\\
    \hline
    Lemmas about \prog{unite}        &                &         663 loc\\
    \hline
    Partial correctness of \prog{dfs} and \prog{dfss} &  &     1575 loc\\
    \hline
    Termination of \prog{dfs} and \prog{dfss} & 13 loc   &      236 loc\\
    \hline
    Total correctness                &                &           5 loc\\
    \hline\hline
    Sum                              &      162 loc   &        2788 loc\\
    \hline
  \end{tabular}
  \caption{Quantitative information about our formalization.}
  \label{tab:effort}
\end{table*}

We now show that the previously defined pre-conditions imply termination of our two functions.

\begin{small}
\begin{lstlisting}[language=isabelle]
theorem dfs-dfss-termination:
  [| v sin vertices; pre-dfs v e |] 
  ==> dfs-dfss-dom (Inl (v,e))
  [| v sin vertices; pre-dfss v e |] 
  ==> dfs-dfss-dom (Inr (v,e))
\end{lstlisting}
\end{small}

The proof proceeds by well-founded induction along the relation \prog{dfs-dfss-term} and then shows that the arguments of recursive calls are indeed related. It makes use of the introduction rule for the predicate \prog{dfs-dfss-dom} that was generated by Isabelle when the two mutually recursive functions were defined.

Putting everything together, we can now prove our main theorem asserting the total correctness of the algorithm.

\begin{small}
\begin{lstlisting}[language=isabelle]
theorem correctness:
  assumes v sin vertices
  shows   sccs (dfs v (init-env v)) = 
          {S . is-scc S /\ (forall n sin S. reachable v n)}
\end{lstlisting}
\end{small}


\section{Discussion of the Proof}
\label{sec:discussion}

\subsection{Effort of formalization}
\label{sec:effort}

Table~\ref{tab:effort} summarizes the overall effort of the formalization. We report the number of lines (definitions and theorems/proofs) for each main category, ignoring comments and empty lines. It should be noted that our proofs are written in the relatively verbose Isar language, which favors readability and maintainability compared to shorter, but unreadable tactic applications.

We start by defining the precedence relation between elements of a list, which does not exist in Isabelle's standard library, and proving elementary lemmas about this relation, as described in Section~\ref{sec:isabelle}. In particular, this relation is a partial order if the list does not contain duplicates, which is the case for the stacks in our formalization.

The second category concerns the formalization of graphs as a locale, the definitions of reachability and (partial and maximal) SCCs, and fundamental lemmas about these concepts, cf.\ Section~\ref{sec:graphs}.

Next, we define the algorithm, including the ``environment'' data structure and the functions \prog{unite}, \prog{dfs}, and \prog{dfss}, cf.\ Section~\ref{sec:formalization}. There is little to prove in this category of the formalization, except for the (trivial) exhaustiveness of the patterns in the recursive definitions, and the transitivity of the relation \prog{sub-env}.

We now define the main invariant \prog{wf-env} and the pre- and post-conditions of the functions \prog{dfs} and \prog{dfss}, and we prove some immediate consequences of these definitions as lemmas for later proofs. The main results of this category are reported in Sections~\ref{sec:invariant} and~\ref{sec:pre-post}.

The following two categories represent the main proof effort of this work. We start by proving auxiliary lemmas about the function \prog{unite}, and in particular the fact that it preserves the main invariant. The partial correctness proofs establish the pre-conditions for each recursive function call, as well as the post-conditions of the functions, assuming their pre-conditions, as reported in Sections~\ref{sec:pre-pre} and~\ref{sec:pre-post}.

We finish the proof by showing that the pre-conditions defined earlier ensure the termination of the functions, and finally conclude total correctness of the algorithm, as explained in Section~\ref{sec:termination}.


\subsection{Related work}
\label{sec:related}

As already noted in the introduction, we are not the first who prove the correctness of an algorithm for computing the SCCs of a graph using a proof assistant. Peter Lammich~\cite{lammich:gabow} used Isabelle/HOL for proving the correctness of Gabow's SCC algorithm. Like Bloemen's algorithm, Gabow's algorithm applies depth-first search and augments partial SCCs whenever a back loop to an already visited vertex of the graph is found. Lammich's proof focuses on efficient code generation, based on the use of his refinement framework~\cite{lammich:refinement} formalized in Isabelle. In this framework, algorithms are represented as monadic functions, and concrete data structures are introduced, for example for representing partial SCCs. In a separate work, Lammich and Neumann contributed significantly to the development of a fully verified executable model checker~\cite{esparza:cava} by developing a framework for verifying depth-first search algorithms~\cite{lammich:depth-first}, including Tarjan's algorithm. In contrast to these works, our proof is based on a more abstract representation of Bloemen's algorithm and its data structures, which leads to higher-level invariants. Indeed, our main objective is not to obtain an efficient sequential implementation of Bloemen's algorithm but rather to pave the way for a verification of the parallel version of that algorithm.

Chen et al.~\cite{chen:tarjan} present a comparison of the proofs of Tarjan's algorithm for computing the SCCs of a graph in the proof assistants Coq, Isabelle, and Why3. The algorithm is represented at a similar level of abstraction as in our proof, leading to comparable proof effort. However, although Tarjan's algorithm is also based on depth-first search, its algorithmic structure is quite different because no partial SCCs are computed along the way, and a maximal SCC is popped from the stack only when a node is determined to be an SCC root at the end of the function call. The primary focus of the presentation in~\cite{chen:tarjan} is on a comparison between the styles of proof and the overall effort required in the three proof assistants.


\section{Conclusion}
\label{sec:conclusion}

In this paper, we reported on the successful proof in Isabelle/HOL of an efficient sequential SCC algorithm proposed by Bloemen et al.~\cite{bloemen:strong}. In particular, we exhibited the inductive invariant \prog{wf-env} that is preserved throughout the execution of the algorithm, as well as pre- and post-conditions for the two mutually recursive functions representing the algorithm. Although our proof is based on arguments given in the correctness proof in Bloemen's thesis, we had to add non-trivial predicates in order to obtain an inductive invariant. For example, the paper-and-pencil proof does not mention the facts that the partial SCCs maintained by the algorithm are maximal w.r.t.\ the current state of knowledge, or that the root of an SCC is the oldest node in depth-first order, but these are necessary for the argument to be conclusive.

As we mentioned previously, the main objective of our work is to serve as a first step towards a machine-checked proof of a parallel implementation of Bloemen's algorithm on a multi-core processor. We therefore formulated our correctness predicates at a high level of abstraction, without considering how the data manipulated by the algorithm would actually be represented in an implementation. We hope that in this way, it will be possible to consider which relaxations of our invariants are possible in a parallel execution of the algorithm. Preliminary experiments with encoding the parallel version in TLA$^+$ and checking several plausible invariants of the algorithm over small graphs using model checking indicate that some invariants break without corrupting the overall result of the SCC computation~\cite{vandepol:exploring}, but that slight modifications of the algorithm are incorrect. We believe that the invariants that we identified for the sequential algorithm, together with the detailed proof, will provide a sound basis for extending the proof to the parallel version.


% As a result of this whole year of work, we successfully proved correctness of an efficient sequential set-based SCC algorithm. In comparison to Tarjan's algorithm, a formal proof of which was written by Chen et. al \cite{chen:tarjan}, this algorithm collapses loops as soon as they are found, thus minimizing the stack size. Our formalization and  proof in Isabelle are quite similar to theirs as they are based on higher-level representations of the algorithms as elementary recursive functions. Hence, our invariants are quite simple compared to those expressed in Lammich's work \cite{lammich:gabow} since he exploits the refinement framework for deriving executable code, resulting in implementable-like representations that make expressing invariants more difficult from a higher-level point of view.

% \begin{itemize}
% \item successfully proved correctness of an efficient sequential SCC algorithm
% \item compare to Tarjan proof (Chen et al.): both are DFS algorithms, the algorithm considered here collapses loops as soon as they are found, minimizing stack size
% \item compare to Lammich's work: he exploits the refinement framework for deriving executable code, we work on a higher-level representation of the algorithm as elementary recursive functions, hence invariants are simpler
% \item objective: stepping stone towards a proof of the parallel version of the algorithm from Bloemen's thesis -- understand which invariants can be relaxed.
% \end{itemize}


\bibliography{bib}
\bibliographystyle{abbrv}

\end{document}
