\documentclass[a4 paper, 12pt]{article}
\usepackage{amsmath, amsthm, amsfonts, amssymb, mathrsfs}
\usepackage{tikzit}
\usepackage{geometry}
\usepackage{hyperref}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{listings}
\usepackage{mathtools}
\usepackage[ruled,vlined, linesnumbered]{algorithm2e}

\input{style.tikzstyles}

% editorial comments in the text or in marginal notes
% 1st argument: initials of the person making the comment,
% 2nd argument: comment to insert
\long\def\ednote#1#2{\par\noindent\framebox{\begin{minipage}{0.99\linewidth}\linespread{.7}\footnotesize #1: #2\end{minipage}}\par}
\newcommand{\edmargin}[2]{\marginpar{\raggedright\linespread{.7}\tiny #1: #2}}

%__________________________________________
\newcommand{\ldb}{\mathopen{\ooalign{\makebox[.4em][l]{$\lbrack$}\cr\makebox[.4em][r]{$\lbrack$}\cr}}}                                                       
\newcommand{\rdb}{\mathclose{\ooalign{\makebox[.4em][l]{$\rbrack$}\cr\makebox[.4em][r]{$\rbrack$}\cr}}}

%__________________________________________

\hypersetup{
    colorlinks=true,
    linktoc=false,
    linkcolor=blue,
    citecolor=blue
}

%__________________________________________
% Colors definition
\definecolor{isa_red}{RGB}{255, 58, 71}
\definecolor{isa_blue}{RGB}{0, 103, 158}
\definecolor{isa_green}{RGB}{0, 157, 97}
\definecolor{isa_dark_green}{RGB}{0,131, 0}
\definecolor{isa_purple}{RGB}{174, 5, 238}
\definecolor{isa_dark_blue}{RGB}{26, 0, 253}

% Isabelle keywords
\newcommand{\stackprec}[3]{\texttt{#1}~\preceq~\texttt{#2}~\text{in}~\texttt{#3}}
\newcommand{\apply}{{\color{isa_red}{apply}}}
\newcommand{\done}{{\color{isa_red}{done}}}
\newcommand{\datatype}{{\color{isa_blue}{datatype}}}
\newcommand{\inductive}{{\color{isa_blue}{inductive}}}
\newcommand{\abbreviation}{{\color{isa_blue}{abbreviation}}}
\newcommand{\thm}{{\color{isa_blue}{theorem}}}
\newcommand{\lm}{{\color{isa_blue}{lemma}}}
\newcommand{\fun}{{\color{isa_blue}{fun}}}
\renewcommand{\locale}{{\color{isa_blue}{locale}}}
\newcommand{\where}{{\color{isa_green}{where}}}
\renewcommand{\and}{{\color{isa_green}{and}}}
\newcommand{\fixes}{{\color{isa_green}{fixes}}}
\newcommand{\assumes}{{\color{isa_green}{assumes}}}
\newcommand{\shows}{{\color{isa_green}{shows}}}
\newcommand{\generic}[1]{{\color{isa_purple}{\textquotesingle#1}}}
\newcommand{\isa}[1]{\small\texttt{\\\noindent#1}}
\newcommand{\blue}[1]{{\color{isa_dark_blue}{#1}}}
\newcommand{\bblue}[1]{{\color{isa_blue}{#1}}}
\newcommand{\green}[1]{{\color{isa_dark_green}{#1}}}
\newcommand{\env}[1]{$(\!|$#1$|\!)$}

\newcommand{\isabelle}[1]{
    \noindent\begin{minipage}{1.1\linewidth}
        \isa{
            #1
        }
    \end{minipage}
}


\lstdefinelanguage{isabelle}{%
    keywords=[1]{type_synonym,datatype,fun,abbreviation,definition,proof,lemma,theorem,corollary},
    keywordstyle=[1]\bfseries\color{isarblue},
    keywords=[2]{where,assumes,shows,and},
    keywordstyle=[2]\bfseries\color{isargreen},
    keywords=[3]{if,then,else,case,of,SOME,let,in,O},
    keywordstyle=[3]\color{isarblue},
}
\lstset{%
  language=isabelle,
  escapeinside={&}{&},
  columns=fixed,
  extendedchars,
  basewidth={0.5em,0.45em},
  basicstyle=\ttfamily,
  mathescape,
}

%__________________________________________
\newcommand\blankpage{%
    \null
    \thispagestyle{empty}%
    \addtocounter{page}{-1}%
    \newpage}

%__________________________________________

% sm: better: \def\NN{\ensuremath{\mathcal{N}}} etc.
\def\NN{\ensuremath{\mathcal{N}}}
\def\GG{\ensuremath{\mathcal{G}}}
\def\VV{\ensuremath{\mathcal{V}}}
\def\EE{\ensuremath{\mathcal{E}}}

\renewcommand\qedsymbol{$\blacksquare$}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}
\newtheorem{corollary}{Corollary}[lemma]
\newtheorem{remark}{Remark}

%__________________________________________

% Node styles
\tikzstyle{white node}=[fill=none, draw=black, shape=circle, tikzit fill=white, tikzit draw=black]
\tikzstyle{red node}=[fill={rgb,255: red,232; green,118; blue,188}, draw=black, shape=circle, tikzit fill={rgb,255: red,232; green,118; blue,188}, tikzit draw=black]
\tikzstyle{blue node}=[fill={rgb,255: red,179; green,191; blue,255}, draw=black, shape=circle, tikzit fill={rgb,255: red,179; green,191; blue,255}, tikzit draw=black]
\tikzstyle{green node}=[fill={rgb,255: red,201; green,255; blue,189}, draw=black, shape=circle, tikzit fill={rgb,255: red,201; green,255; blue,189}, tikzit draw=black]

\tikzstyle{arrow}=[>]
\tikzstyle{new style 0}=[fill=none, draw=red, shape=circle, tikzit fill=none]
\tikzstyle{arrow}=[<--]
\tikzstyle{new edge style 2}=[- - -]

% Edge styles
\tikzstyle{right arrow}=[->]
\tikzstyle{right red arrow}=[->, draw=red, tikzit draw=red]
\tikzstyle{left arrow}=[<-]
\tikzstyle{left red arrow}=[<-, draw=red, tikzit draw=red]
\tikzstyle{right dashed arrow}=[->, dashed=1, dash pattern=on 1mm off 1mm, draw=red]
\tikzstyle{left dashed arrow}=[<-, dashed=1, dash pattern=on 1mm off 1mm, draw=red]
\tikzstyle{blue fill}=[-, fill={rgb,255: red,179; green,191; blue,255}, draw=none, tikzit draw=none, tikzit fill={rgb,255: red,213; green,207; blue,255}]
\tikzstyle{green fill}=[-, fill={rgb,255: red,201; green,255; blue,189}, draw=none, tikzit draw=none, tikzit fill={rgb,255: red,213; green,255; blue,208}]
\tikzstyle{red fill}=[-, fill={rgb,255: red,232; green,118; blue,188}, draw=none, tikzit draw=none, tikzit fill={rgb,255: red,232; green,118; blue,118}]

%-----------------------------------------------------------------

\begin{document}
\newgeometry{margin=2cm}
\begin{titlepage}
    \begin{figure}[!h]
        \centering
        \includegraphics[height = .1\textwidth]{img/logoartem.png}
        \hspace{1cm}
        \includegraphics[height = .1\textwidth]{img/logoloria.jpg}
        \hspace{1cm}
        \includegraphics[height = .1\textwidth]{img/logoUL.png}
    \end{figure}
    \vspace{3cm}

    \begin{center}
%        \huge{Strongly connected components algorithms : parallelization and proofs}
%        \huge{Formal methods and assisted proofs: application to strongly connected components algorithms}
        \huge{Formal verification of an algorithm for computing strongly connected components}
    \end{center}
    \vspace{3 cm}
    \begin{center}
        Vincent Trélat
        \BlankLine
        \BlankLine
        Supervized by Stephan Merz
    \end{center}
    \vspace{3 cm}
    \begin{center}
        \textit{\today}
    \end{center}
    \vspace{3 cm}
    \begin{center}
        ***
    \end{center}
    
\end{titlepage}
\restoregeometry

\blankpage

\hfill
\begin{minipage}{.45\textwidth}
    \textit{
    My warmest and most sincere thanks to Stephan Merz, who has been a great help in the development the whole project and who reviewed this paper with great care.
    }
\end{minipage}

\pagebreak


\tableofcontents

\pagebreak

\section{Preamble}
\subsection{Academic context}
This research work was carried out as part of my curriculum at the French \href{https://mines-nancy.univ-lorraine.fr}{École des Mines de Nancy}. All documents such as codes or source papers are available on a \href{https://github.com/VTrelat/Tarjan}{GitHub repository}.

\subsection{Formal methods}
Formal methods are a field of computer science related to mathematical logic and reasoning. The whole purpose of the discipline is to give precise, mathematical definitions to computer science concepts. Formal methods find applications in a variety of fields, both concrete, such as the railway industry or self-driving cars, and abstract, such as computational architecture. Although the purpose of giving such definitions is to enable formal verification, many techniques besides theorem proving, such as model-based testing, run-time monitoring, model checking etc.\ are used.

\subsection{Isabelle (HOL)}
\begin{quote}
    ``Isabelle is a generic proof assistant. It allows mathematical formulas to be expressed in a formal language and provides tools for proving those formulas in a logical calculus.''
\end{quote}
\begin{flushright}
    \href{https://isabelle.in.tum.de/}{isabelle.in.tum.de}
\end{flushright}
Isabelle \cite{nipkow_isabellehol_2002} is a really powerful proof assistant coming with a higher order logic (HOL) proving environment. Isabelle proofs are written in the Isar (``intelligible semi-automated reasoning'') language that is designed to make proofs readable and comprehensible for a mathematically inclined reader, with minimal overhead introduced by the formalism. In fact, ``assistant'' refers to the fact that the machine checks the proof provided by the user, in contrast to automatic theorem proving where the machine finds the proof itself. The tools for automation are intended to help the user write the proof at a conveniently high level, without needing to work at the level of a logical calculus, for example.

\section{Introduction}

The objective of this project is to mechanize a proof of correctness of a set-based algorithm inspired by Tarjan's algorithm \cite{TarjanDFS} for computing the strongly connected components of a graph. A similar work has been done on Tarjan's algorithm \cite{TarjanMerz}. The algorithm was first published in Vincent Bloemen's thesis \cite{bloemen_strong_2019} who furthermore gives and explains a few invariants, and was later reused in \cite{bloemen_multi-core_2016} with the aim of working on a parallel version of the algorithm.

In this report, a few arguments are given for the understanding of the formal proof. Some important invariants are explained and the main lemmas are briefly detailed. Some of the proofs will be explicitly given in slightly less rigorous mathematical terms for the sake of better understandability.

\section{Formalisation}
\subsection{Graphs and reachability}
\begin{definition}[Directed graph]
    A directed graph \GG\xspace is the data of a set of nodes \VV\xspace and a set of oriented edges \EE.
\end{definition}

\begin{definition}[Reachability]
    For two vertices $x$ and $y$ of \VV, the reachability relation is noted ``$\Rightarrow^*$'' such that $x \Rightarrow^* y$ iff $x$ can reach $y$ in \GG.
\end{definition}

\begin{remark}
    The relation $\Rightarrow^*$ is in fact the transitive closure of the binary relation $\Rightarrow$ defining edges in a graph.
\end{remark}

\begin{definition}[Successors set for a node]
    Let $\mathcal{G} = (\mathcal{V}, \mathcal{E})$ and $v \in \mathcal{V}$. The set of successors of $v \in \VV$ is \textsc{Post}($v$) such that:
    \begin{equation*}
        \textsc{Post}(v) = \{w \in \VV~|~(v,w) \in \mathcal{E}\}
    \end{equation*}
\end{definition}

\subsection{Strongly connected components}
\subsubsection{Directed graphs}\label{sec:directedgraphs}

\begin{definition}[SCC]
    Let \GG = (\VV, \EE) be a directed graph.
$\mathcal{C} \subseteq \mathcal{V}$ is a strongly connected component (SCC) of \GG if:
\begin{equation*}
    \forall x, y \in \mathcal{C}, (x \Rightarrow^* y) \wedge (y \Rightarrow^* x)
\end{equation*}
\textit{i.e.} there is a path between every $x$ and $y$ in $\mathcal{C}$.
\BlankLine
$\mathcal{C}$ is maximal, or $\mathcal{C}$ is a maximal SCC of \GG \xspace if there is no other SCC containing $\mathcal{C}$, \textit{i.e.} if:
\begin{equation*}
    \forall \mathcal{X}, (\mathcal{C} \subseteq \mathcal{X}) \wedge (\forall x, y \in \mathcal{X}, (x \Rightarrow^* y) \wedge (y \Rightarrow^* x)) \Longrightarrow \mathcal{C} = \mathcal{X}
\end{equation*}
\end{definition}

\begin{definition}(Strong connectedness)
Let \GG = (\VV, \EE) be a directed graph. \GG \xspace is strongly connected if \VV \xspace is a SCC.
\end{definition}

\subsubsection{Examples}
Let us give some visual examples of a strongly connected component in a directed graph.

\begin{figure}[!h]
    \centering
    \begin{subfigure}[t]{.49\textwidth}
        \ctikzfig{example2}
        \subcaption{Strongly connected component}\label{fig:example1_a}
    \end{subfigure}
    \begin{subfigure}[t]{.49\textwidth}
        \ctikzfig{example3}
        \subcaption{Not strongly connected component}\label{fig:example1_b}
    \end{subfigure}
    \caption{Basic example of what is a small SCC}\label{fig:example1}
\end{figure}

In \textsc{Figure} \ref{fig:example1}, two small directed graphs are shown. The first one (\textsc{Figure} \ref{fig:example1_a}) is strongly connected, but the second one (\textsc{Figure} \ref{fig:example1_b}) is not because the node $x$ is not reachable from $w$ for instance.

\begin{figure}[!h]
    \ctikzfig{exampleSCC}
    \caption{Example of a graph where each colored set of nodes is a -- maximal -- SCC\label{fig:exampleSCC}}
\end{figure}

Let us give another example on a larger graph. \textsc{Figure} \ref{fig:exampleSCC} shows a directed graph on which each colored set of nodes is a -- maximal -- SCC. Therefore, one can informally understand that SCCs roughly describe the cycles in a graph.

\begin{figure}[!h]
    \ctikzfig{exampleSCCreduced}
    \caption{Reduced visualization of the graph represented in \textsc{Figure} \ref{fig:exampleSCC}}\label{fig:exampleSCCreduced}
\end{figure}

One may want to have a more general view of and consider only the distinct components of a graph. Thus, the graph show on \textsc{Figure} \ref{fig:exampleSCC} can be reduced to a graph in which the previously colored nodes are replaced by a single node containing all the nodes of the same SCCs, \textit{i.e.} all the equivalent nodes, as shown in \textsc{Figure} \ref{fig:exampleSCCreduced}.



\section{A sequential set-based algorithm}
\subsection{Formalisation}
\begin{definition}[SCC mapping]
    In the following algorithm, the SCCs are progressively tracked in a collection of disjoint sets through a map $\mathcal{S} : \mathcal{V} \longrightarrow \mathcal{P}(\mathcal{V})$, where $\mathcal{P}(\mathcal{V})$ is the powerset of \VV, s.t. the following invariant is maintained:
    \begin{equation}\label{invariant:Sdisjoint}
        \forall v, w \in \mathcal{V}, w\in \mathcal{S}(v) \Longleftrightarrow \mathcal{S}(v) = \mathcal{S}(w)
    \end{equation}
\end{definition}

\begin{remark}
    In the following, the same notation $\mathcal{S}$ will be used to denote both the function defined above and the induced equivalence relation\footnote{For the relation $(x, y) \mapsto x \in \mathcal{S}(y) ~\land~ y \in \mathcal{S}(x) $} since $\mathcal{S}$ associates to each node its class of equivalence. 
\end{remark}

\begin{remark}
    In particular, $\forall v \in \mathcal{V}, v \in \mathcal{S}(v)$.
\end{remark}

\begin{definition}[SCC union]
    Let \textsc{Unite} be the function taking as parameters a map $\mathcal{S}$ as defined previously and two vertices $u$ and $v$ of $\mathcal{V}$ such that $\textsc{Unite}(\mathcal{S}, u, v)$ merges the two mapped sets $\mathcal{S}(u)$ and $\mathcal{S}(v)$ and maintains the invariant (\ref{invariant:Sdisjoint}) by updating $\mathcal{S}$.
\end{definition}
Let us give an example:\\
Let $\mathcal{V} = \{u,v,w\}$ such that there is the following mapping: $\mathcal{S}(u) = \{u\}$ and $\mathcal{S}(v) = \mathcal{S}(w) = \{v,w\}$.\\
Then, $\textsc{Unite}(\mathcal{S}, u, v) = \mathcal{S}(u) = \mathcal{S}(v) = \mathcal{S}(w) = \{u,v,w\}$.  

\subsection{The algorithm}
This section gives a pseudo-code of the set-based algorithm for which we will write a formal proof. See \cite{bloemen_strong_2019} for the original paper.
\BlankLine
The algorithm only takes as input a directed graph $\GG = (\VV, \EE)$ and a starting node $v_0$ as the root of its exploration. It returns a partition \texttt{SCCs} of \VV \xspace being the set of SCCs in the subgraph of \GG\xspace reachable from $v_0$, where each element of \texttt{SCCs} is a maximal strongly connected components of \GG. The equivalence relation $\mathcal{S}$ is initialized so that at the beginning, each node is its own SCC. That is, $\mathcal{S}(v) = \{v\}$ for all $v \in \VV$, or seen as a set of disjoint sets: $\mathcal{S} = \bigcup \{ \{v\} \mid v \in \VV \}$.\\
\BlankLine

\noindent
\begin{algorithm}[H]\label{alg:seqsetbased}
    \SetAlgoLined
    \KwData{\GG = (\VV, \EE), $v_0$\;}
    \KwResult{\texttt{SCCs}\;}
    Initialize an empty set \texttt{EXPLORED}\;
    Initialize an empty set \texttt{VISITED}\;
    Initialize an empty stack \texttt{R}\;
    Initialize $\mathcal{S} \colon v \in \VV \mapsto \{v\}$\;
    setBased($v_0$)\;
    \SetKwProg{Function}{function}{}{}
    \Function{setBased: $v \in \mathcal{V} \rightarrow \texttt{None}$}{
        $\texttt{VISITED} := \texttt{VISITED} \cup \{v\}$\;
        \texttt{R.push($v$)}\;
        \ForEach{$w\in \texttt{POST(v)}$}{
            \If{$w\in \texttt{EXPLORED}$}{
                continue\;
            }
            \ElseIf{$w \notin \texttt{VISITED}$}{
                setBased($w$)\;
            }
            \Else{
                \While{$\mathcal{S}(v) \neq \mathcal{S}(w)$}{
                    $r := \texttt{R.pop()}$\;
                    $\texttt{UNITE}(\mathcal{S}, r, \texttt{R.top()})$\;
                }
            }
        }
        \If{$v = \texttt{R.top()}$}{
            \textbf{report SCC} $\mathcal{S}(v)$\;
            $\texttt{EXPLORED} := \texttt{EXPLORED} \cup \mathcal{S}(v)$\;
            \texttt{R.pop()}\;
        }
    }
    
    \caption{Sequential set-based SCC algorithm}
\end{algorithm}


\subsection{Informal proof}
Note that this proof is said informal only because it is not checked by a mechanized proof assistant. Both logical and mathematical arguments developed below are absolutely relevant.

\begin{lemma}(First invariant)\label{lemma:disjointness}
    \begin{equation*}
        \forall x, y \in \texttt{R}, x\neq y \implies \mathcal{S}(x) \cap \mathcal{S}(y) = \varnothing
    \end{equation*}
    Note the misuse of the set notation $x, y \in \texttt{R}$ which just means that $x$ and $y$ are in the stack \texttt{R}.
\end{lemma}

\begin{proof}
    Let us consider the stacj $\texttt{R}$ at some step of the algorithm. Let $x = \text{hd}(R)$, \textit{i.e.} the first element of the stack.
    \BlankLine
    
    Then let $y \in \texttt{POST}(x)$. If $y$ is already explored, then we can skip it.
    \BlankLine
    Otherwise, if $y$ is not in the visited set, then we explore it by calling the function \texttt{setBased} on $y$ and since $y$ is not visited, $\mathcal{S}(y) = \{y\}$.
    \BlankLine
    Finally, if $y$ is in the visited set, it means that either $y$ in on the stack or it has a representative $z \in \mathcal{S}(y)$ on the stack. However, one can understand that the \textit{while} loop below is executed until the equivalence relation is fully updated. In particular, the invariant is maintained, and there is only one representative of $\mathcal{S}(y)$ on the stack, being the earliest visited node in $\mathcal{S}(y)$ the traversal.

\end{proof}

\begin{remark}\label{rem:rootSCC}
    It is worth noting that the representative of a partial — with respect to the final result — SCC is the earliest node of this SCC to be visited regarding the graph traversal. This ensures that a representative on the stack is in fact the root of its SCC.
\end{remark}

\begin{lemma}
    \begin{equation*}
        \biguplus_{r \in \texttt{R}} \mathcal{S}(r) = \textsc{Live} := \textsc{Visited} \setminus \textsc{Explored}
    \end{equation*}
\end{lemma}

\begin{proof}
    The disjointness of all on-stack partial SCCs is given by lemma \ref{lemma:disjointness}. Nodes from $\textsc{Visited} \setminus \textsc{Explored}$ have a (unique) representative in \texttt{R} because they are being processed. So, $\textsc{Live} \subseteq \texttt{R}$.
    \BlankLine
    By L.6-7 of Algorithm \ref{alg:seqsetbased}, $\textsc{Visited} \subseteq \texttt{R}$.
    L.9-10 ensure that no explored node is pushed in \texttt{R}.
    L.24-25 keep the invariant by unstacking explored nodes from \texttt{R}, so $\texttt{R} \cap \textsc{Explored} = \varnothing$. Thus, $\texttt{R} = \textsc{Visited} \setminus \textsc{Explored} = \textsc{Live}$.
\end{proof}

\begin{corollary}[Strong version]\label{cor:cor1}
    \begin{equation*}
        \forall v \in \textsc{Live}, \exists!~r \in \texttt{R} \cap \mathcal{S}(v), \mathcal{S}(v) = \mathcal{S}(r)
    \end{equation*}
\end{corollary}
\begin{proof}
    Let $v \in \textsc{Live} = \displaystyle{\biguplus_{r \in \texttt{R}} \mathcal{S}(r)}$. $v$ is in a unique partial SCC $\mathscr{S} := \mathcal{S}(v)$. Because of lemma \ref{lemma:disjointness}, there cannot exist $x \neq y \in \texttt{R}$ s.t. $\mathcal{S}(x) = \mathcal{S}(y) = \mathscr{S}$. Thus, there exists a unique $x \in \texttt{R}$ s.t. $\mathcal{S}(x) = \mathscr{S}$ (and $x\in \texttt{R} \cap \mathscr{S}$).
\end{proof}

\begin{corollary}[Weak version]\label{cor:cor2}
    \begin{equation*}
        \forall v \in \mathcal{V}, \forall w \in \textsc{Post}(v), w \in \textsc{Live} \implies \exists w' \in \texttt{R}, \mathcal{S}(w') = \mathcal{S}(w)
    \end{equation*}
\end{corollary}

\begin{proof}
    Holds because of corollary \ref{cor:cor1}.
\end{proof}

\begin{remark}
    In the algorithm \ref{alg:seqsetbased}, this property is maintained by L.16-18. These lines also illustrate how the algorithm ``reads'' the SCCs. Corollary \ref{cor:cor2} shows that when the mapped representatives of the top two nodes of \texttt{R} are united (until $\mathcal{S}(w') = \mathcal{S}(v) = \mathcal{S}(w)$ since $w'$ has a path to $v$), then all united components are in the same SCC.
\end{remark}

\begin{remark}\label{rem:proof}
    Because \texttt{R} only contains exactly one representative for each partial SCC (corollary \ref{cor:cor1} and remark \ref{rem:rootSCC}), after each step of the main loop -- \textit{i.e.} the DFS -- every partial SCC is actually maximal in the current set of visited nodes.
\end{remark}

\begin{theorem}
    The sequential algorithm \ref{alg:seqsetbased} is correct, \textit{i.e.} it returns the set of maximal SCCs reachable from $v_0$.
\end{theorem}
\begin{proof}
    Holds by remark \ref{rem:proof}.
\end{proof}

An example of the execution of the algorithm is given in \nameref{appendix}, in the section \ref{appendix:exec_ex}.


\subsection{Prerequisites for the formal proof}
Since the informal proof seems to be convincing, the formal -- checked automatically -- proof can be written in Isabelle (HOL) based on the basis of the reasoning developed above.

\subsubsection{Environment setup}\label{envdef}
The first definitions should be the different structures used in the algorithm. In particular, a record containing all the sets needed and described in the pseudo-code of algorithm \ref{alg:seqsetbased}. The environment has a generic type parameter, which is used to represent the type of the nodes in the graph (often integers):

\isabelle{
    {\color{isa_blue}record} \generic{v} env =\\
    $~~~\mathcal{S}$ :: "\generic{v} $\Rightarrow$ \generic{v} set"\\
    $~~~$explored :: "\generic{v} set"\\
    $~~~$visited :: "\generic{v} set"\\
    $~~~$sccs :: "\generic{v} set set"\\
    $~~~$stack :: "\generic{v} list"
}

\BlankLine
\BlankLine
\BlankLine

The following lines define a graph structure and some useful natural relations:

\isabelle{
    {\locale} graph =\\
    $~~~$\fixes{} vertices :: "\generic{v} set" \and{} successors :: "\generic{v} $\Rightarrow$ \generic{v} set"\\
    $~~~$\assumes{} vfin: "finite vertices"\\
    $~~~$\and{} sclosed: "$\forall$ \green{x} $\in$ vertices. successors \green{x} $\subseteq$ vertices"
}

\BlankLine
\BlankLine
\BlankLine

The use of \texttt{successors} instead of an adjacency matrix, for instance, is a consequence of the fact that the algorithm is only concerned with the topological ordering of the nodes. For instance, nodes can represent integers, logical propositions or sets of states in a proving system for example.

\subsubsection{Reachability}
Now that graphs are defined, the reachability can be defined. Defining an edge is simply some rewriting of being a successor of one node.

\BlankLine

\isabelle{
    \abbreviation{} edge \where\\
    $~~~$"edge \green{x y} $\equiv$ \green{y} $\in$ successors \green{x}"
}

\BlankLine
\BlankLine
\BlankLine

\noindent

Isabelle allows the definition of recursive functions. Such a definition must guarantee that any recursive call takes an argument that decreases (according to some measure function) with respect to the original argument. This is typically the case for functions that follow the definition of an algebraic type (integers, lists, trees, etc.). In addition, Isabelle allows inductive definitions of relations where two values are related if it is possible to justify this relation by applying a finite number of times the definition clauses of the relation. In our case, this applies to the definition of reachability where two nodes are connected if they are identical or if the first node has a successor from which the second node is already known to be reachable.

\BlankLine
\BlankLine

Although a recursive definition has to be based on some underlying inductive definition -- which is simply not available for graphs -- it expresses both the positive and negative information\footnote{In this case, the positive information designates the fact of being reachable and the negative information designates the fact of not being reachable.} whereas the inductive one only expresses the positive information directly. Therefore, with an inductive definition, the negative information has to be proved. One would be right to argue that it would be more convenient to be able to tell without proving it that two nodes are not reachable from each other, but this does not interest us for the following and this is actually more difficult than proving the reachability. Another important point is that there is no datatype for a recursive definition, especially in this case with the transitive closure of the $\Rightarrow^*$ relation. Thus, the inductive definition is not a choice but is necessary. Isabelle provides a construction for inductive predicate definitions, which is appropriate here because the two clauses represent the reflexive case and the extension of reachability by prepending an edge. This will be particularly useful in the proofs.

\BlankLine
\BlankLine

\isabelle{
    \inductive{} reachable \where\\
    $~~~$reachable\_refl[iff]: "reachable \green{x x}"\\
    $~\mid$ reachable\_succ[elim]: "$\ldb$edge \green{x y}; reachable \green{y z}$\rdb \Longrightarrow$ reachable \green{x z}"\\
}

In order to be able to use those relations in the proofs later, it is essential to prove a list of lemmas, namely all the different natural properties that Isabelle cannot deduce\footnote{That is an abuse of language. The idea is for example that for the moment, there is no formal link between \texttt{edge} and \texttt{reachable}. The goal is to formalize it so Isabelle is logically able to both use and simplify some results in the proofs.} from nothing\footnote{There is actually a theorem fetcher that is particularly useful to find a basic set of lemmas.}. For instance, the following lemmas are essential.

\isabelle{
\lm{} succ\_reachable:\\
$~~~~~$\assumes{} "reachable {\color{isa_dark_blue}x y}" \and{} "edge {\color{isa_dark_blue}y z}"\\
$~~~~~$\shows "reachable {\color{isa_dark_blue}x z}"\\
$~~~~~${\color{isa_blue}using} assms {\color{isa_blue}by} induct auto\\
}
Mathematical writing: $\forall x, \forall y, \forall z, (x \Rightarrow^* y \wedge y \Rightarrow z) \Longrightarrow x \Rightarrow^* z$

\begin{remark}
    Note that this is the ``mirror'' of clause \texttt{reachable\_succ} (appending an edge).
\end{remark}

\isabelle{
\lm{} reachable\_trans:\\
$~~~~~$\assumes{} y: "reachable \blue{x y}" \and{} z: "reachable \blue{y z}"\\
$~~~~~$\shows{} "reachable \blue{x z}"\\
$~~~~~${\color{isa_blue}using} assms {\color{isa_blue}by} induct auto\\
}
Mathematical writing: $\forall x, \forall y, \forall z, (x \Rightarrow^* y \wedge y \Rightarrow^* z) \Longrightarrow x \Rightarrow^* z$\\

As the formal proofs will enventually deal with strongly connected components, it is also essential to formally define SCCs. For the purpose of the proof, the property of being a SCC is called \texttt{sub\_scc} and being a \textit{maximal} SCC is called \texttt{is\_scc} :

\isabelle{
{\color{isa_blue}definition} is\_subscc \where\\
$~~~~~$"is\_subscc S $\equiv \forall$ x $\in$ S. $\forall$ y $\in$ S. reachable x y"\\
}
Mathematical writing: A set $S$ is a SCC if $\forall x \in S, \forall y \in S, x \Rightarrow^* y$

\isabelle{
{\color{isa_blue}definition} is\_scc \where\\
$~~~~~$"is\_scc S $\equiv$ S $\neq$ \{\} $\wedge$ is\_subscc S\\
$~~~~~\wedge$ ($\forall$ S'. S $\subseteq$ S' $\wedge$ is\_subscc S' $\longrightarrow$ S' = S)"\\
}
Mathematical writing: A non-empty SCC $S$ is maximal if for all SCC $S'$, $S \subseteq S' \Longrightarrow S'=S$\\

Once again, there are some lemmas to prove which are deduced using Isabelle from the above definitions, such as giving conditions on when an element can be added to a SCC, or that two vertices that are reachable from each other are in the same SCC, or that two SCCs having a common element are identical, etc.

\subsubsection{Ordering relation}\label{sec:orderingrelation}
In the proof, a precedence relation\footnote{In fact, a partial order is being defined on stacks.}noted \blue{$\bullet~\preceq~\bullet~\text{in}~\bullet$} will be needed on the stack. Let $x$ and $y$ be two nodes and $R$ be a stack. Informally, $x$ precedes $y$ in $R$ if $y$ was pushed in $R$ before $x$ (see \textsc{Figure} \ref{fig:stackorder}).

\begin{figure}[!h]
    \ctikzfig{stackorder}
    \caption{The ordering relation on stacks\label{fig:stackorder}}
\end{figure}

\begin{definition}[Ordering relation]
    Let $x$ and $y$ be two nodes and $xs$ be a stack.
    \begin{equation*}
        x \preceq y~\text{in}~xs \equiv \exists~h,~\exists~r,~(xs = h @ [x] @ r) \wedge (y \in [x]@r)
    \end{equation*}
\end{definition}


The idea is to later use the following property: if $x \preceq y~\text{in}~xs$, then $y \Rightarrow^* x$.\\
It is defined in Isabelle as follows:\\

\isabelle{
    {\color{isa_blue}definition} precedes ("\_ $\preceq$ \_ in \_" [100,100,100] 39) \where\\
$~~~~~$"{\color{isa_dark_green}x} $\preceq$ {\color{isa_dark_green}y} in {\color{isa_dark_green}xs} $\equiv$ $\exists${\color{isa_dark_green}h} {\color{isa_dark_green}r}. {\color{isa_dark_green}xs} = {\color{isa_dark_green}h} @ ({\color{isa_dark_green}x} \# {\color{isa_dark_green}r}) $\wedge$ {\color{isa_dark_green}y} $\in$ set ({\color{isa_dark_green}x} \# {\color{isa_dark_green}r})"\\
}

All the different properties (\textit{i.e.} lemmas) which follow this definition in the Isabelle implementation are detailed in the natural mathematical writing in the \nameref{appendix}. The right part of the notation represents the orders of priority for each operand since $\preceq$ is an infix operator.

\subsubsection{Implementation of the algorithm}

In the algorithm \ref{alg:seqsetbased}, the SCCs are progressively tracked in \texttt{sccs} and the equivalence relation $\mathcal{S}$ is updated with the \textsc{Unite} function. Note that the function written in Isabelle is different from the \textsc{Unite} function introduced earlier. From now on, \texttt{unite} designates the following function, which was first written as a recursive function as follows:

\BlankLine

\isabelle{
    {\color{isa_blue}function} unite :: "\generic{v} $\Rightarrow$ \generic{v} $\Rightarrow$ \generic{v} env $\Rightarrow$ \generic{v} env" \where{}\\
    "\blue{unite} \green{v w e} =\\
    $~~~$({\color{isa_blue}if} ($\mathcal{S}$ \green{e v} = $\mathcal{S}$ \green{e w}) \bblue{then} \green{e}\\
    $~~~$\bblue{else let} \green{r} = hd(stack \green{e});\\
    $~~~~~~~~~~~~$\green{r'}= hd(tl(stack \green{e}));\\
    $~~~~~~~~~~~~$\green{joined} = $\mathcal{S}$ \green{e r} $\cup$ $\mathcal{S}$ \green{e r};\\
    $~~~~~~~~~~~~$\green{e'}= \green{e}\env{\\
    $~~~~~~~~~~~~~~~$stack := tl(stack \green{e}),\\
    $~~~~~~~~~~~~~~~\mathcal{S}$ := ($\lambda$ n. \bblue{if} n $\in$ \green{joined} \bblue{then} \green{joined} \bblue{else} $\mathcal{S}$ \green{e n})\\
    $~~~~~~~~~~~~$}\\
    $~~~$\bblue{in} \blue{unite} \green{v w e'})"\\
    $~~~$\bblue{by} pat\_completeness auto
}

\BlankLine

However, this definition makes the proofs too difficult due to the recursion. A non-recursive version was therefore written:

\BlankLine
\label{unite_def}
\isabelle{
    \bblue{definition} unite :: "\generic{v} $\Rightarrow$ \generic{v} $\Rightarrow$ \generic{v} env $\Rightarrow$ \generic{v} env" \where{}\\
    $~~~$"\blue{unite} \green{v w e} $\equiv$\\
    $~~~~~~$\bblue{let} \green{pfx} = takeWhile ($\lambda$\green{x}. \green{w} $\notin$ $\mathcal{S}$ \green{e x}) (stack \green{e});\\
    $~~~~~~~~~~$\green{sfx} = dropWhile ($\lambda$\green{x}. \green{w} $\notin$ $\mathcal{S}$ \green{e x}) (stack \green{e});\\
    $~~~~~~~~~~$\green{cc} = $\bigcup$ \{$\mathcal{S}$ \green{e x} $|$ \green{x}. \green{x} $\in$ set \green{pfx} $\cup$ \{hd \green{sfx}\}\}\\
    $~~~~~~$\bblue{in}  \green{e}\env{$\mathcal{S}$ := $\lambda$\green{x}. \bblue{if} \green{x} $\in$ \green{cc} \bblue{then} \green{cc} \bblue{else} $\mathcal{S}$ \green{e x}, stack := \green{sfx}}"
}
    
\BlankLine
\BlankLine
\BlankLine

The idea of this definition is to create a partition of \texttt{stack e = pfx @ sfx} such that \texttt{pfx} contains the nodes which are to be merged into \texttt{$\mathcal{S}$ e w} and \texttt{sfx} contains the root of \texttt{$\mathcal{S}$ e w} followed by the rest of the stack. Then, \texttt{cc} -- which stands for \textit{connected component} -- contains all the nodes which are equivalent to \texttt{w} in the sub-graph currently explored. The function \texttt{takeWhile} applied to a boolean function \texttt{P}\footnote{\texttt{P :: \generic{a} $\Rightarrow$ bool}} seen as a property and a list \texttt{xs} returns the elements of \texttt{xs} which satisfy \texttt{P} and stops at the first element not satisfying \texttt{P}. The function \texttt{dropWhile} is the opposite of \texttt{takeWhile}. Both the recursive and non-recursive versions of \texttt{unite} are equivalent -- it should be proved though -- in the context of this report. In fact, the non-recursive definition is intended to be simpler for the proof because it avoids introducing separate pre- and post-conditions for the function and proving such a ``contract''.

\BlankLine

Now that the environment is set up, the actual algorithm -- seen as a function -- can be implemented.
Since Isabelle does not support loops, the implementation will be split into two mutually recursive functions. The main function is called \texttt{dfs} and takes its name after the Depth First Search algorithm because the algorithm \ref{alg:seqsetbased} roughly consists in a deep traversal of a graph. The second function is called \texttt{dfss} and represents the \textit{foreach} loop of the algorithm \ref{alg:seqsetbased}. The two functions are mutually recursive because they recursively call each other. In particular, \texttt{dfss} will call both \texttt{dfs} and itself, depending on the case. Their implementation is as follows:

\BlankLine

\isabelle{
    {\color{isa_blue}{function}} dfs :: "\generic{v} $\Rightarrow$ \generic{v} env $\Rightarrow$ \generic{v} env" \and{}\\
    $~~~~~~~~~~$dfss:: "\generic{v} $\Rightarrow$ \generic{v} set $\Rightarrow$ \generic{v} env $\Rightarrow$ \generic{v} env" \where\\
    "{\color{isa_dark_blue}dfs} {\color{isa_dark_green}v e} =\\
    $~~~~~$({\color{isa_blue}{let}} {\color{isa_dark_green}e1} = {\color{isa_dark_green}e}\env{visited := visited e $\cup$ \{{\color{isa_dark_green}v}\}, stack := ({\color{isa_dark_green}v} \# stack {\color{isa_dark_green}e})};\\
    $~~~~~~~~~~${\color{isa_dark_green}e'} = {\color{isa_dark_blue}dfss} {\color{isa_dark_green}v} (successors {\color{isa_dark_green}v}) {\color{isa_dark_green}e1}\\
    $~~~~~${\color{isa_blue}{in if}} {\color{isa_dark_green}v} = hd(stack {\color{isa_dark_green}e'})\\
    $~~~~~~~~~~${\color{isa_blue}{then}} {\color{isa_dark_green}e'}\env{sccs:=sccs {\color{isa_dark_green}e'} $\cup$ {$\mathcal{S}$ {\color{isa_dark_green}e' v}}, explored:=explored {\color{isa_dark_green}e'} $\cup$ ($\mathcal{S}$ {\color{isa_dark_green}e' v}), stack:=tl(stack {\color{isa_dark_green}e'})}\\
    $~~~~~~~~~~${\color{isa_blue}else} {\color{isa_dark_green}e'})"\\
    | "{\color{isa_dark_blue}dfss} {\color{isa_dark_green}v vs e} =\\
    $~~~~~$({\color{isa_blue}if} {\color{isa_dark_green}vs} = \{\} {\color{isa_blue}then} {\color{isa_dark_green}e}\\
    $~~~~~${\color{isa_blue}else} ({\color{isa_blue}let} {\color{isa_dark_green}w} = SOME {\color{isa_dark_green}x}. {\color{isa_dark_green}x} $\in$ {\color{isa_dark_green}vs}\\
    $~~~~~~~~~~${\color{isa_blue}in} ({\color{isa_blue}let} {\color{isa_dark_green}e'} = ({\color{isa_blue}if} {\color{isa_dark_green}w} $\in$ explored {\color{isa_dark_green}e} {\color{isa_blue}then} {\color{isa_dark_green}e}\\
    $~~~~~~~~~~~~~~~~~~~${\color{isa_blue}else if} {\color{isa_dark_green}w} $\notin$ visited {\color{isa_dark_green}e} {\color{isa_blue}then} {\color{isa_dark_blue}dfs} {\color{isa_dark_green}w e}\\
    $~~~~~~~~~~~~~~~~~~~${\color{isa_blue}else} unite {\color{isa_dark_green}v w e})\\
    $~~~~~~~~~~~~~~${\color{isa_blue}in} {\color{isa_dark_blue}dfss} {\color{isa_dark_green}v} ({\color{isa_dark_green}v} - \{{\color{isa_dark_green}w}\}) {\color{isa_dark_green}e'})))"\\
    $~~~${\color{isa_blue}by} pat\_completeness (force\bblue{+})\\
}

The two last keywords require explanations as well : \texttt{pat\_completeness} stands for \textit{pattern completeness} and ensures that there is no missing patterns. The method \texttt{force} finishes the proof of pattern completeness, the proof of termination remains open, and it would actually show that these are well-defined functions. {\texttt{force} is more aggressive in instantiation than \texttt{auto} and seems to find the right instance.

\subsubsection{General scheme}
As the algorithm is composed of two mutually recursive functions, the correctness of the algorithm is proved by mutual induction on the functions with the help of the environment structure (cf \ref{envdef}). Since both \texttt{dfs} and \texttt{dfss} are quite complex, the proof is split into several parts. The idea is to prove for each function that its execution given some pre-conditions on the input environment implies some post-conditions on the output environment. Then, it has to be made for the mutually recursive calls as well, so that given the same pre-conditions on one function, the pre-conditions on the other function are also satisfied. Finally, it has to be proved that if the pre-conditions are satisfied for one function, and if the pre-conditions imply the post-conditions on the other function, then the post-conditions are also satisfied for the first function.

\subsubsection{Well-formedness of the environment}
The whole proof relies on one big invariant regarding the environment structure. It defines the fact for an environment to be well-formed. This invariant is a conjunction of several properties and is defined as follows:

\isabelle{
    \bblue{definition} wf\_env \where{}\\
    $~~~$"\blue{wf\_env} \green{e} $\equiv$\\
    $~~~~~~$distinct (stack \green{e})\\
    $~~~~\wedge$ set (stack \green{e}) $\subseteq$ visited \green{e}\\
    $~~~~\wedge$ explored \green{e} $\subseteq$ visited \green{e}\\
    $~~~~\wedge$ explored \green{e} $\cap$ set (stack \green{e}) = \{\}\\
    $~~~~\wedge$ ($\forall$ \green{v} \green{w}. \green{w} $\in$ $\mathcal{S}$ \green{e} \green{v} $\longleftrightarrow$ ($\mathcal{S}$ \green{e} \green{v} = $\mathcal{S}$ \green{e} \green{w}))\\
    $~~~~\wedge$ ($\forall$\green{v} $\in$ set (stack \green{e}).$\forall$ \green{w} $\in$ set (stack \green{e}).\green{v} $\neq$ \green{w} $\longrightarrow$ $\mathcal{S}$ \green{e} \green{v} $\cap$ $\mathcal{S}$ \green{e} \green{w} = \{\})\\
    $~~~~\wedge$ ($\forall$ \green{v}. \green{v} $\notin$ visited \green{e} $\longrightarrow$ $\mathcal{S}$ \green{e} \green{v} = \{\green{v}\})\\
    $~~~~\wedge$ $\bigcup$ \{$\mathcal{S}$ \green{e} \green{v} $|$ \green{v}. \green{v} $\in$ set (stack \green{e})\} = visited \green{e} - explored \green{e}\\
    $~~~~\wedge$ ($\forall$ \green{x} \green{y}. \green{x} $\preceq$ \green{y} in stack \green{e} $\longrightarrow$ reachable \green{y} \green{x})\\
    $~~~~\wedge$ ($\forall$ \green{x}. is\_subscc ($\mathcal{S}$ \green{e} \green{x}))\\
    $~~~~\wedge$ ($\forall$ \green{x} $\in$ explored \green{e}. $\forall$ \green{y}. reachable \green{x} \green{y} $\longrightarrow$ \green{y} $\in$ explored \green{e})\\
    $~~~~\wedge$ ($\forall$ \green{S} $\in$ sccs \green{e}. is\_scc \green{S})"
}

\BlankLine
\BlankLine

Let us take a closer look to this invariant, taken in the same order as the definition above:
\begin{itemize}
    \item[$\bullet$] First, the stack is a list of distinct elements.
    \item[$\bullet$] All elements of the stack are visited.
    \item[$\bullet$] The set of explored nodes is a subset of the set of visited nodes.
    \item[$\bullet$] Explored nodes cannot be in the stack.
    \item[$\bullet$] The three next properties are about the equivalence relation $\mathcal{S}$.
    \item[$\bullet$] The union of the sets of equivalent nodes in the stack is equal to the set of visited nodes minus the set of explored nodes.
    \item[$\bullet$] A node in the stack can reach all nodes before it in the stack (\textit{i.e.} pushed later).
    \item[$\bullet$] $\mathcal{S}$ represents a set of strongly connected components (not maximal).
    \item[$\bullet$] For all explored nodes, the sub-graph induced by their successors is totally explored.
    \item[$\bullet$] \texttt{sccs} is a set of maximal SCCs
\end{itemize}
\noindent
These properties are natural and most of them are easy to prove. Actually, there is a bit of redundancy here. For example, the second and fourth conjunct follow from the fifth and eighth. This is not a bad thing per se since it may help automatic proof, but could be discussed.

\BlankLine
\BlankLine

It is also useful to induce a notion of monotonicity on the environments during the execution of the algorithm. This is defined as follows through the definition of an ordering relation on environments:

\isabelle{
\bblue{definition} sub\_env \where\\
"\blue{sub\_env} \green{e e'} $\equiv$\\
$~~~~$visited \green{e} $\subseteq$ visited \green{e'}\\
$~~$$\wedge$ explored \green{e} $\subseteq$ explored \green{e'}\\
$~~$$\wedge$ ($\forall$ \green{v}. $\mathcal{S}$ \green{e v} $\subseteq$ $\mathcal{S}$ \green{e' v})\\
$~~$$\wedge$ ($\bigcup$\{$\mathcal{S}$ \green{e v} $|$ \green{v}. \green{v} $\in$ set (stack \green{e})\}) $\subseteq$ ($\bigcup$\{$\mathcal{S}$ \green{e' v} $|$ \green{v}. \green{v} $\in$ set (stack \green{e'})\})"
}

In particular, the last conjunct expresses the fact that the equivalence relation on the stack is monotonic. This is a useful property as it explicitly gives a monotonic behaviour on the environment structure -- hence its name -- during the execution of the algorithm, even though we do not have an inductive rule on environments. Besides, this property is transitive, which will be used in the proofs.

\BlankLine
\BlankLine

\subsubsection{\texttt{dfs} pre- and post-conditions}
The pre-conditions of \texttt{dfs} are rather simple. The environment must be well-formed and the node must not be visited. There is also a condition on the reachability of the nodes in the stack and the node on which the function is called, but once again this condition is rather natural to consider since \texttt{dfs} is performing a DFS graph traversal:

\isa{
\bblue{definition} pre\_dfs \where\\
$~~$"pre\_dfs \green{v e} $\equiv$\\
$~~~~$wf\_env \green{e}\\
$~~$$\wedge$ \green{v} $\notin$ visited \green{e}\\
$~~$$\wedge$ ($\forall$ \green{n} $\in$ set (stack \green{e}). reachable \green{n v})"
}

\BlankLine
\BlankLine

The post-conditions are a little more complex since it has to consider the new environment with the new visited / explored nodes, the new state of the stack and the updates in $\mathcal{S}$:

\isabelle{
\bblue{definition} post\_dfs \where\\ 
"post\_dfs \green{v prev\_e e} $\equiv$\\
$~~~~$wf\_env \green{e}\\
$~~\wedge$ ($\forall$ \green{x}. reachable \green{v} \green{x} $\longrightarrow$ \green{x} $\in$ visited e)\\
$~~\wedge$ sub\_env \green{prev\_e} \green{e}\\
$~~\wedge$ ($\forall$ \green{n} $\in$ set (stack \green{e}). reachable \green{n} \green{v})\\
$~~\wedge$ ($\exists$ \green{ns}. stack \green{prev\_e} = \green{ns} @ (stack \green{e}))\\
$~~\wedge$ ($\forall$ \green{m n}. $\stackprec{\green{m}}{\green{n}}{\green{prec\_e}}$ $\longrightarrow$ \\ $~~~~~~$ ($\forall$ \green{u} $\in$ $\mathcal{S}$ \green{prev\_e m}. reachable \green{u} \green{v} $\wedge$ reachable \green{v} \green{n} $\longrightarrow$ $\mathcal{S}$ \green{e m} = $\mathcal{S}$ \green{e n}))\\
$~~\wedge$ ((\green{v} $\in$ explored \green{e} $\wedge$ stack \green{e} = stack \green{prev\_e}) $\lor$ \\
$~~~~~~$ (\green{v} $\in$ $\mathcal{S}$ \green{e} (hd (stack \green{e}))) $\wedge$ \\
$~~~~~~$ ($\exists$ \green{n} $\in$ set (stack \green{prev\_e}). $\mathcal{S}$ \green{e v} = $\mathcal{S}$ \green{e n}))"
}

\BlankLine
\BlankLine
\BlankLine

Let us give some explanations:
\begin{itemize}
    \item[$\bullet$] The environment must be well-formed.
    \item[$\bullet$] The sub-graph induced by the nodes reachable from the node on which the function is called must be totally visited.
    \item[$\bullet$] The previous environment must be a sub-environment of the new one (\textit{i.e.} there is a monotonic ordering on the environments).
    \item[$\bullet$] The condition of reachability on the stack from the pre-condition must remain satisfied.
    \item[$\bullet$] The new stack is a suffix of the previous one (\textit{i.e.} it expressively represents the structure of FIFO stack).
    \item[$\bullet$] The last one is easier to understand: either $v$ is explored and the stack considered before and after the execution of the function has not changed, or the head of the stack is the representative of $v$ and $v$ had a representative in the previous stack.
\end{itemize}

\subsubsection{\texttt{dfss} pre- and post-conditions}
The pre-conditions on \texttt{dfss} are also rather simple, except the sixth conjunct which expresses the fact that before the execution of the function, if a node $n$ on the stack is reachable from $v$, then either $v \in \mathcal{S}(n)$, or $n$ is reachable from a successor of $v$. Once again, this condition has to be equated with the fact that all nodes on stack can reach $v$ (fifth conjunct in the following definition). The definition is as follows:

\isabelle{
\bblue{definition} pre\_dfss \where{}\\
"pre\_dfss \green{v vs e} $\equiv$\\
$~~~~$wf\_env \green{e}\\
$~~\land$ \green{v} $\in$ visited \green{e}\\
$~~\land$ \green{vs} $\subseteq$ successors \green{v}\\
$~~\land$ ($\forall$ \green{n} $\in$ set (stack \green{e}). reachable \green{n v})\\
$~~\land$ (stack \green{e} $\neq$ [])\\
$~~\land$ (\green{v} $\in$ $\mathcal{S}$ \green{e} (hd (stack \green{e})))"
}

\BlankLine
\BlankLine
\BlankLine

The post-conditions on \texttt{dfss} are less complicated than the post-conditions of \texttt{dfs} and can easily be understood with the explanations of the other invariants:

\isabelle{
\bblue{definition} post\_dfss \where\\
"post\_dfss \green{v vs prev\_e e} $\equiv$\\
$~~~~$wf\_env \green{e}\\
$~~\land$ ($\forall$ \green{w} $\in$ \green{vs}. $\forall$ \green{x}. reachable \green{w x} $\longrightarrow$ \green{x} $\in$ visited \green{e})\\
$~~\land$ sub\_env \green{prev\_e e}\\
$~~\land$ ($\forall$ \green{n} $\in$ set (stack \green{e}). reachable \green{n v})\\
$~~\land$ (stack \green{e} $\neq$ [])\\
$~~\land$ ($\forall$ \green{n} $\in$ set (stack \green{e}). reachable \green{v n} $\longrightarrow$ \green{v} $\in$ $\mathcal{S}$ \green{e n})\\
$~~\land$ ($\exists$ \green{ns}. stack \green{prev\_e} = \green{ns} @ (stack \green{e}))\\
$~~\land$ (\green{v} $\in$ $\mathcal{S}$ \green{e} (hd (stack \green{e})))"
}

\subsection{Formal proof}
\subsubsection{\texttt{pre\_dfs} implies \texttt{pre\_dfss}}
This lemma assumes that the pre-conditions on \texttt{dfs} are satisfied and shows that it implies that the pre-conditions on \texttt{dfss} are satisfied on the environment on which \texttt{dfs} is called, \textit{i.e.} the environment for which $v$ was pushed on the stack and added to the set of visited nodes.

\BlankLine

\isabelle{
\bblue{lemma} pre\_dfs\_pre\_dfss:\\
$~~~$\assumes{} "pre\_dfs \blue{v e}"\\
$~~~$\shows{} "pre\_dfss \blue{v} (successors \blue{v}) \\ $~~~~~~~~~~~~$\blue{e}\env{visited := visited \blue{e} $\cup$ \{\blue{v}\}, stack := \blue{v} \# stack \blue{e}}"
}

\BlankLine

The proof is quite straightforward, except for the reachability of elements in the stack. Let $e'$ be the environment on which \texttt{dfss} will be called. Then, we want to show the following proposition:

\begin{equation*}
    \forall x, y,~x \preceq y \text{ in stack } e' \Longrightarrow y \Rightarrow^* x
\end{equation*}

\begin{proof}
    Let $x$ and $y$ be two nodes on the stack of $e'$ such that $x \preceq y \text{ in stack } e'$.
    \begin{itemize}
        \item[if $x = v$:] then we have to show that $y \Rightarrow^* v$. If $y = v$, it is trivial, otherwise, $y$ is in the stack of $e$ and $v$ is reachable from $y$ from the pre-condition of \texttt{dfs} (fourth conjunct in the definition of \texttt{dfs}).
        \item[if $x \neq v$:] then $x$ is in the stack of $e$ and $x \preceq y \text{ in stack } e$. From the pre-condition of \texttt{dfs}, $y \Rightarrow^* x$.
    \end{itemize}
        
\end{proof}

\subsubsection{\texttt{pre\_dfss} implies \texttt{pre\_dfs}}
This lemma fixes a node $w$ and assumes the pre-conditions on \texttt{dfss} on a node $v$, a set (of successors) $vs$ and an environment $e$. It assumes that $w$ is a successor of $v$ that is not visited, and it shows that the pre-conditions on \texttt{dfs} on $w$ the same environment $e$ are satisfied.

\isabelle{
\lm{} pre\_dfss\_pre\_dfs:\\
$~~~$\fixes{} \blue{w}\\
$~~~$\assumes{} "pre\_dfss \blue{v vs e}" and "\blue{w} $\notin$ visited \blue{e}" and "\blue{w} $\in$ \blue{vs}"\\
$~~~$\shows{} "pre\_dfs \blue{w e}"
}

\BlankLine
\BlankLine

The proof of the lemma is very simple since all conditions of \texttt{pre\_dfs} can be deduced from the conditions of \texttt{pre\_dfss}.

\subsubsection{\texttt{pre\_dfs} implies \texttt{post\_dfs}}\label{lemma:pre_post_dfs}
This lemma is probably the most important lemma -- and the most difficult to show -- in the proof of the algorithm. It assumes that the pre-condition on \texttt{dfs} are satisfied and shows that the post-condition on \texttt{dfs} are satisfied. It is stated as follows:

\isabelle{
\lm{} pre\_dfs\_implies\_post\_dfs:\\
$~~~$\fixes{} \blue{v e}\\
$~~~$\green{defines} "\blue{e1} $\equiv$ \blue{e}\env{visited := visited \blue{e} $\cup$ \{v\}, stack := (v \# stack \blue{e})}"\\
$~~~$\green{defines} "\blue{e'} $\equiv$ dfss \blue{v} (successors \blue{v}) \blue{e1}"\\
$~~~$\assumes{} 1: "pre\_dfs \blue{v e}"\\
$~~~~~~~$\and{} 2: "dfs\_dfss\_dom (Inl(\blue{v}, \blue{e}))"\\
$~~~~~~~$\and{} 3: "post\_dfss \blue{v} (successors \blue{v}) \blue{e1 e'}"\\
$~~~$\shows{} "post\_dfs \blue{v e} (dfs \blue{v e})"
}

\BlankLine
\BlankLine

Note that the definitions of $e_1$ and $e'$ follow from the definition of \texttt{dfs} which relies -- in an \textit{if} statement -- on the fact that $v = \text{hd } (\text{stack } e)$ or not, therefore the proof also considers this split of cases.

\BlankLine

The first case assumes that $v = \text{hd}(\text{stack }e')$. Then with the second assumption ($v$ and $e$ are in the domain of definition of \texttt{dfs}), we can show that \texttt{dfs} returns the following environment:
\BlankLine
\noindent
$\texttt{dfs}~v~e = e'(\!|\texttt{sccs}:=\texttt{sccs}~e' \cup \{\mathcal{S}~e'~v\},\\
~~~~~~~~~~~~~~~~~~\texttt{explored}:=\texttt{explored}~e' \cup (\mathcal{S}~e'~v),\\
~~~~~~~~~~~~~~~~~~\texttt{stack}:=\texttt{tl}(\texttt{stack}~e')|\!)"$
\BlankLine
That is, it returns an environment $e_2 := \text{dfs}~v~e$ obtained from $e'$ in which a new SCC, namely $\mathcal{S}~e'~v$, is added. The different conjuncts in the definition of \texttt{post\_dfs} are then shown one by one. Some useful things to note -- and prove -- are the following:

\begin{itemize}
    \item $\text{stack }e_2 = \text{tl}(\text{stack }e')$, and since $v$ is the head of the stack of $e'$, we can show that $\text{stack }e_1 = \text{stack }e'$. The main idea is to use, from the assumption 3, the fact that:
    \begin{equation*}
        \exists~ns,~\text{stack } e_1 = ns~@~(\text{stack }e')
    \end{equation*}

    \item The equivalence relation is the same for $e'$ and $e_2$: $\forall x, \mathcal{S}~e'~x = \mathcal{S}~e_2~x$
    \item It is easy to show that $e$ is a sub-environment of $e_1$ (i.e. $\texttt{sub\_env}~e~e_1$). We can also show that $e_1$ is a sub-environment of $e_2$, which is much more difficult. However, the proofs in Isabelle are quite simple to read and understand. \textit{In fine}, by transitivity of the relation \texttt{sub\_env}, $e$ is a sub-environment of $e_2$.
    \item Showing that $\mathcal{S}~e'~v$ is a maximal SCC in the environment $e_2$ is a tricky part. The proof uses a contradiction-based reasoning and the fact that the equivalence relation is the same for $e'$ and $e_2$ to find a node being in a bigger SCC containing $\mathcal{S}~e'~v$ but not in $\mathcal{S}~e'~v$, and exploit the reachability from and to $v$ and the assumption 3.
\end{itemize}

In the second case, $v$ is not the head of the stack of $e'$, therefore $\texttt{dfs}~v~e = e'$ and the proof is much easier thanks to the post-condition on \texttt{dfss}, \textit{i.e.} assumption 3.

\subsubsection{Partial correctness}
This lemma shows two things:
\BlankLine
\noindent
\texttt{dfs\_dfss\_dom (Inl(v,e)) $\land$ pre\_dfs v e} $\Longrightarrow$ \texttt{post\_dfs v e (dfs v e)}
\BlankLine
\noindent
\texttt{dfs\_dfss\_dom (Inr(v,e)) $\land$ pre\_dfss v vs e} $\Longrightarrow$ \texttt{post\_dfss v vs e (dfss v vs e)}

\BlankLine
\noindent
where \texttt{dfs\_dfss\_dom (Inl(v,e))} -- respectively \texttt{Inr(v, e)} -- is the assumption that \texttt{v} and \texttt{e} are in the domain of definition of \texttt{dfs} (respectively \texttt{dfss}).
\BlankLine
The first proposition is a consequence of the lemma \nameref{lemma:pre_post_dfs}.
\BlankLine
For the second proposition, we need to write the proof according to the definition of \texttt{dfss}. That is, we need to show the following proposition:

\BlankLine

With these assumptions:
\begin{itemize}
    \item $\texttt{dfs\_dfss\_dom} (\texttt{Inr}(v,vs,e))$
    \item $\texttt{pre\_dfss}~v~vs~e$
    \item $vs \neq \varnothing$ and \\$\forall w \in vs,  w \notin \texttt{explored } e~\land~w \notin \texttt{visited } e~\land~\texttt{pre\_dfs}~w~e \Longrightarrow \texttt{post\_dfs}~w~e~(\texttt{dfs}~w~e)$
    \item let $e' =
    \begin{dcases}
		e & w \in \texttt{explored}~e \\
		\texttt{dfs}~v~e & w \in \texttt{visited}~e \\
        \texttt{unite}~v~w~e & \text{otherwise}
	\end{dcases}$\\
    $vs \neq \varnothing$ and \\$\forall w \in vs, \texttt{pre\_dfss}~v~(vs - \{w\})~e' \Longrightarrow \texttt{post\_dfss}~v~(vs - \{w\})~e'~(\texttt{dfss}~v~(vs~-~\{w\})~e')$
\end{itemize}
\noindent
We need to show the post-condition of \texttt{dfss}:
\begin{equation*}
    \texttt{post\_dfss}~v~vs~e~(\texttt{dfss}~v~vs~e)s
\end{equation*}

If the set of successors $vs$ is empty, then the post-condition of \texttt{dfss} is satisfied.
Otherwise, the proof is split according to the cases in the definition of $e'$. In the first case, $w$ is in the set of explored nodes of $e$. Hence, $e' = e$. The proof is rather straightforward thanks to the assumption on \texttt{pre\_dfss}.

\BlankLine

The following case, \textit{i.e.} $w \in \texttt{visited }e$ is much more complicated. In this case, $e' = \texttt{dfs}~v~e$. Although the proof remains straightforward, the different properties are more difficult to establish. The main idea is to use the fact that $\texttt{post\_dfs}~w~e~e'$ is satisfied to show the pre-condition : $\texttt{pre\_dfss}~v~vs-\{w\}~e$. From the assumptions, we can obtain the post-condition : $\texttt{post\_dfss}~v~vs-\{w\}~e~e'$. There still remains some work to do inorder to show that this implies the final post-condition, \textit{i.e.} that $\texttt{post\_dfss}~v~vs-\{w\}~e~(\texttt{dfss}~v~vs-\{w\}~e)$ is satisfied.

\BlankLine

In the last case, the function \texttt{unite} is called to compute the new environment $e'$. The proof uses the local variables defined in the definition of \texttt{unite}, \textit{i.e.} \texttt{pfx}, \texttt{sfx} and \texttt{cc} (see \ref{unite_def}). In particular, it is important to note that $\texttt{stack e} = \texttt{pfx } @ \texttt{ sfx}$ and $w$ is represented by a node in the stack being the head of \texttt{sfx}. A visual representation of the stack is given in \textsc{Figure \ref{fig:partial_correctness_unite}}. Morally, it is easy to understand that because of the cycle drawn on \textsc{Figure \ref{fig:partial_correctness_unite}}, $\mathcal{S}$ should be updated in the new environment so that all components of $\mathcal{S}$ for each node of \texttt{sfx} should be merged together.

\begin{figure}[!h]
    \ctikzfig{partial_correctness_unite}
    \caption{Representation of \texttt{stack e} in the case $w \in \texttt{ visited } e$. The black arrows represent reachability in both directions because the definition of a representative on the stack states that both nodes are in the same component of $\mathcal{S}$ for the environment $e$.}\label{fig:partial_correctness_unite}
\end{figure}

\BlankLine

The approach is similar to the previous case : we prove the pre-condition on \texttt{dfss} and use the hypotheses to show the post-condition of \texttt{dfss}. The rest consists in proving the post-condition of \texttt{dfss} on $v$, $vs - \{w\}$ and the new environment $e'$ and the environment return by \texttt{dfss} implies the final post-condition.


\section{Conclusion}
\subsection{What has been done ?}
The proof of correctness is almost done. The model and the invariants we have come up with are quite comprehensive and coherent now. We regularly test newer invariants with TLC, a model checker for specifications written in TLA+. Thus, we also have a TLA+ version of this algorithm, although it is not really the same implementation. However, as we juste use it to verify a few properties on specific examples, it is just meant to give us a better feeling of confidence or find counter examples. I've been working on this project for almost a year, and yet it's only been a month or two that I really feel like I understand the algorithm.

\subsection{What is missing ?}
In the proof of correctness, some intermediate proofs are still skipped. It is mainly due to some former invariants that were deleted because they were wrong.

\BlankLine

Another important missing piece is the proof of termination of the functions. In order to achieve this, we need to define a measure and find a quantity that strictly decreases for that measure. In \texttt{sub\_env}, the inclusions are not strict. An idea would be to consider the complementary set of visited between two calls of \texttt{dfs} as a set getting strictly smaller.

\subsection{My experience}
Before starting the project, I had no knowledge of formal methods. I had to learn it quickly in one month and as I went along. I liked it right away. As I am very attached to rigour, there is a very addictive side to wanting to demonstrate everything. This is why I decided to pursue my career in the field of formal methods.
\BlankLine
It was also my first experience in the world of research. It was an opportunity to confirm my desire to do basic research, and I also found a domain. I was also able to meet several of the researchers of the \href{https://www.loria.fr/fr/la-recherche/les-equipes/mosel-veridis/}{MOSEL-VERIDIS} team at \href{https://www.loria.fr/en/}{LORIA} in Nancy, as well as \href{https://cs.au.dk/~jaco/}{Jaco Van de Pol} who is the supervised the thesis of Vincent Bloemen \cite{bloemen_strong_2019}.


\pagebreak

\section{Appendix}\label{appendix}
\subsection{Some lemmas}
Those lemmas refer to the precedence relation introduced in \textsc{Section} \ref{sec:orderingrelation}.
\BlankLine
Let $x, y, z$ be three nodes, and let $xs, ys, zs$ be three lists of nodes representing stacks.\\
By abuse of language, if an element is on a stack, it is in the set of elements contained in the stack so the following statement can be written: $x$ is on $xs \Longleftrightarrow x \in xs$. However, $xs$ in not seen as the set representing $xs$ since an element may occur several times in a stack.\\
The operator $@$ denotes the concatenation and operates on two lists: $[x_0, \dots, x_n] @ [y_0, \dots, y_m] = [x_0, \dots, x_n, y_0, \dots, y_m]$.\\

\begin{flushleft}
    (i)
$x \preceq y~\text{in}~xs \Longrightarrow (x \in xs)\wedge(y \in xs)$
\end{flushleft}
\begin{flushleft}
    (ii)
$y \in [x] @ xs \Longrightarrow x \preceq y~\text{in}~([x] @ xs)$
\end{flushleft}

\begin{flushleft}
    (iii)
    $x \neq z \Longrightarrow (x \preceq y~\text{in}~([z] @ zs) \Longrightarrow x \preceq y ~\text{in}~zs)$
\end{flushleft}

\begin{flushleft}
    (iv)
    $(y \preceq x~\text{in}~([x] @ xs)) \wedge (x \notin xs) \Longrightarrow (x = y)$
\end{flushleft}

\begin{flushleft}
    (v)
    $y \in (ys @ [x]) \Longrightarrow y \preceq x~\text{in}~(ys @ [x] @ xs)$
\end{flushleft} 

\begin{flushleft}
    (vi)
    $(x \preceq x~\text{in}~xs) = (x \in xs)$
\end{flushleft}

\begin{flushleft}
    (vii)
    $x \preceq y~\text{in}~xs \Longrightarrow x \preceq y~\text{in}~(ys @ xs)$
\end{flushleft}

\begin{flushleft}
    (viii)
    $x \notin ys \Longrightarrow (x \preceq y~\text{in}~(ys @ xs) \Longleftrightarrow x \preceq y~\text{in}~xs)$
\end{flushleft}

\begin{flushleft}
    (ix)
    $x \preceq y~\text{in}~xs \Longrightarrow x \preceq y~\text{in}~(xs @ ys)$
\end{flushleft}

\begin{flushleft}
    (x)
    $y \notin ys \Longrightarrow x \preceq y~\text{in}~(xs @ ys) \Longleftrightarrow x \preceq y~\text{in}~xs$
\end{flushleft}

\begin{flushleft}
    (xi)(transitivity)
    $(x \preceq y~\text{in}~xs) \wedge (y \preceq z~\text{in}~xs) \wedge \underset{\text{all elements of $xs$ are distinct}}{\underbrace{(\forall~0 \leq i < j \leq \text{length}(xs), xs[i] \neq xs[j])}} \Longrightarrow x \preceq z~\text{in}~xs$
\end{flushleft}

\begin{flushleft}
    (xi)(antisymmetry)
    $(x \preceq y~\text{in}~xs) \wedge (y \preceq x~\text{in}~xs) \wedge \underset{\text{all elements of $xs$ are distinct}}{\underbrace{(\forall~0 \leq i < j \leq \text{length}(xs), xs[i] \neq xs[j])}} \Longrightarrow x = y$
\end{flushleft}

\subsection{An example of execution of algorithm \ref{alg:seqsetbased}.}\label{appendix:exec_ex}
This sequence of figures is meant to be read from left to right. Brown nodes are nodes which have not been visited yet. Pink nodes are nodes which are being visited, \textit{i.e.} which are on stack. Other colors are for reported SCCs.

\begin{figure}
    \begin{subfigure}[t]{0.5\textwidth}
        \ctikzfig{slides_seqalg1}
    \end{subfigure}
    \begin{subfigure}[t]{0.5\textwidth}
        \ctikzfig{slides_seqalg2}
    \end{subfigure}
    \begin{subfigure}[t]{0.5\textwidth}
        \ctikzfig{slides_seqalg3}
    \end{subfigure}
    \begin{subfigure}[t]{0.5\textwidth}
        \ctikzfig{slides_seqalg4}
    \end{subfigure}
    \begin{subfigure}[t]{0.5\textwidth}
        \ctikzfig{slides_seqalg5}
    \end{subfigure}
    \begin{subfigure}[t]{0.5\textwidth}
        \ctikzfig{slides_seqalg6}
    \end{subfigure}
\end{figure}
\begin{figure}
    \begin{subfigure}[t]{0.5\textwidth}
        \ctikzfig{slides_seqalg7}
    \end{subfigure}
    \begin{subfigure}[t]{0.5\textwidth}
        \ctikzfig{slides_seqalg8}
    \end{subfigure}
    \begin{subfigure}[t]{0.5\textwidth}
        \ctikzfig{slides_seqalg9}
    \end{subfigure}
    \begin{subfigure}[t]{0.5\textwidth}
        \ctikzfig{slides_seqalg10}
    \end{subfigure}
    \begin{subfigure}[t]{0.5\textwidth}
        \ctikzfig{slides_seqalg11}
    \end{subfigure}
    \begin{subfigure}[t]{0.5\textwidth}
        \ctikzfig{slides_seqalg12}
    \end{subfigure}
\end{figure}

\pagebreak

% bibliography
\bibliographystyle{plain}
\bibliography{references}


\end{document}x